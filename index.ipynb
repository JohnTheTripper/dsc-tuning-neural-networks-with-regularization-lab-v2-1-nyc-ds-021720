{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Neural Networks with Regularization - Lab \n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll use a train-test partition as well as a validation set to get better insights about how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Apply early stopping criteria with a neural network \n",
    "- Apply L1, L2, and dropout regularization on a neural network  \n",
    "- Examine the effects of training with more data on a neural network  \n",
    "\n",
    "\n",
    "## Load the Data\n",
    "\n",
    "Run the following cell to import some of the libraries and classes you'll need in this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in the file `'Bank_complaints.csv'`. Load and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preview the dataset\n",
    "df = pd.read_csv('Bank_complaints.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Overview\n",
    "\n",
    "Before you begin to practice some of your new tools such as regularization and optimization, let's practice munging some data as you did in the previous section with bank complaints. Recall some techniques:\n",
    "\n",
    "* Sampling in order to reduce training time (investigate model accuracy vs data size later on)\n",
    "* Train - test split\n",
    "* One-hot encoding your complaint text\n",
    "* Transforming your category labels \n",
    "\n",
    "## Preprocessing: Generate a Random Sample\n",
    "\n",
    "Since you have quite a bit of data and training neural networks takes a substantial amount of time and resources, downsample in order to test your initial pipeline. Going forward, these can be interesting areas of investigation: how does your model's performance change as you increase (or decrease) the size of your dataset?  \n",
    "\n",
    "- Generate a random sample of 10,000 observations using seed 123 for consistency of results. \n",
    "- Split this sample into `X` and `y` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>I am being contacted by a debt collector for p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product                       Consumer complaint narrative\n",
       "0  Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n",
       "1  Student loan  I am being contacted by a debt collector for p..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['product', 'consumer_complaint_narrative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>consumer_complaint_narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>I am being contacted by a debt collector for p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        product                       consumer_complaint_narrative\n",
       "0  Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n",
       "1  Student loan  I am being contacted by a debt collector for p..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the data\n",
    "random.seed(123)\n",
    "sample_index = random.sample(range(1,60000), 10000)\n",
    "#sampled_df = df[sample_index]\n",
    "\n",
    "# Split the data into X and y\n",
    "y = df['product'][sample_index]\n",
    "X = df['consumer_complaint_narrative'][sample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3432                Student loan\n",
       "17543                Credit card\n",
       "5714                Student loan\n",
       "50395                   Mortgage\n",
       "26689    Bank account or service\n",
       "                  ...           \n",
       "44820                   Mortgage\n",
       "19376                Credit card\n",
       "767                 Student loan\n",
       "21705    Bank account or service\n",
       "37807              Consumer Loan\n",
       "Name: product, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3432     My husband graduated during the recession, had...\n",
       "17543    To Whom It May Concern : On XXXX XXXX, 2016 a ...\n",
       "5714     Good morning, My School XXXX is now closed due...\n",
       "50395    Our loan was originated on  XXXX   XXXX ,  XXX...\n",
       "26689    My mother had passed in 2009 and XXXX XXXX wro...\n",
       "                               ...                        \n",
       "44820    Wells Fargo offers mortgage customers the abil...\n",
       "19376    I set up auto pmt on my account by filling in ...\n",
       "767      After graduating in 2013, I had n't found a jo...\n",
       "21705    I was charged XXXX apparently for a XXXX. Cent...\n",
       "37807    I received an pre-authorization offer for a pe...\n",
       "Name: consumer_complaint_narrative, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "- Split the data into training and test sets \n",
    "- Assign 1500 obervations to the test set and use 42 as the seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1500, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set \n",
    "\n",
    "As mentioned in the previous lesson, it is good practice to set aside a validation set, which is then used during hyperparameter tuning. Afterwards, when you have decided upon a final model, the test set can then be used to determine an unbiased perforance of the model. \n",
    "\n",
    "Run the cell below to further divide the training data into training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500\n",
      "1500\n",
      "1000\n",
      "7500\n",
      "1500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_final))\n",
    "print(len(X_test))\n",
    "print(len(X_val))\n",
    "print(len(y_train_final))\n",
    "print(len(y_test))\n",
    "print(len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: One-hot Encoding the Complaints\n",
    "\n",
    "As before, you need to do some preprocessing before building a neural network model. \n",
    "\n",
    "- Keep the 2,000 most common words and use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "- Transform the training, validate, and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "# Only keep the 2000 most common words \n",
    "\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "\n",
    "tokenizer.fit_on_texts(X_train_final) \n",
    "# one_hot_results = tokenizer.texts_to_matrix(X_train_final, mode='binary') \n",
    "\n",
    "X_train_tokens = tokenizer.texts_to_matrix(X_train_final, mode='binary') \n",
    "X_val_tokens = tokenizer.texts_to_matrix(X_val, mode='binary') \n",
    "X_test_tokens = tokenizer.texts_to_matrix(X_test, mode='binary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 2000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Encoding the Products\n",
    "\n",
    "Similarly, now transform the descriptive product labels to integers labels. After transforming them to integer labels, retransform them into a matrix of binary flags, one for each of the various product labels.  \n",
    "  \n",
    "> **Note**: This is similar to your previous work with dummy variables. Each of the various product categories will be its own column, and each observation will be a row. In turn, each of these observation rows will have a 1 in the column associated with it's label, and all other entries for the row will be zero. \n",
    "\n",
    "Transform the training, validate, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the product labels to numerical values\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "\n",
    "y_train_lb = lb.fit_transform(y_train_final)\n",
    "y_val_lb = lb.fit_transform(y_val)\n",
    "y_test_lb = lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test_lb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Baseline Model \n",
    "\n",
    "Rebuild a fully connected (Dense) layer network:  \n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions (since you are dealing with a multiclass problem, classifying the complaints into 7 classes) \n",
    "- Use a `'softmax'` activation function for the output layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a baseline neural network model using Keras\n",
    "random.seed(123)\n",
    "from keras import models\n",
    "from keras import layers\n",
    "baseline_model = models.Sequential()\n",
    "baseline_model.add(layers.Dense(50, activation = 'relu', input_shape = (2000,)))\n",
    "baseline_model.add(layers.Dense(25, activation = 'relu'))\n",
    "baseline_model.add(layers.Dense(7, activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model\n",
    "\n",
    "Compile this model with: \n",
    "\n",
    "- a stochastic gradient descent optimizer \n",
    "- `'categorical_crossentropy'` as the loss function \n",
    "- a focus on `'accuracy'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "baseline_model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='sgd',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                100050    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 182       \n",
      "=================================================================\n",
      "Total params: 101,507\n",
      "Trainable params: 101,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "- Train the model for 150 epochs in mini-batches of 256 samples \n",
    "- Include the `validation_data` argument to ensure you keep track of the validation loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1500 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 1.9468 - acc: 0.1563 - val_loss: 1.9303 - val_acc: 0.1893\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.9170 - acc: 0.2001 - val_loss: 1.9052 - val_acc: 0.2333\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.8920 - acc: 0.2436 - val_loss: 1.8808 - val_acc: 0.2647\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.8671 - acc: 0.2685 - val_loss: 1.8560 - val_acc: 0.2847\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.8399 - acc: 0.2935 - val_loss: 1.8287 - val_acc: 0.3040\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.8094 - acc: 0.3184 - val_loss: 1.7972 - val_acc: 0.3333\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.7753 - acc: 0.3512 - val_loss: 1.7626 - val_acc: 0.3553\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.7380 - acc: 0.3809 - val_loss: 1.7253 - val_acc: 0.3727\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.6976 - acc: 0.4067 - val_loss: 1.6860 - val_acc: 0.3973\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.6547 - acc: 0.4341 - val_loss: 1.6431 - val_acc: 0.4287\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.6087 - acc: 0.4645 - val_loss: 1.5985 - val_acc: 0.4487\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.5601 - acc: 0.4849 - val_loss: 1.5515 - val_acc: 0.4707\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.5091 - acc: 0.5091 - val_loss: 1.5011 - val_acc: 0.4980\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.4561 - acc: 0.5321 - val_loss: 1.4507 - val_acc: 0.5147\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.4020 - acc: 0.5585 - val_loss: 1.3985 - val_acc: 0.5360\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.3469 - acc: 0.5804 - val_loss: 1.3461 - val_acc: 0.5467\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.2928 - acc: 0.6052 - val_loss: 1.2954 - val_acc: 0.5727\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.2386 - acc: 0.6255 - val_loss: 1.2510 - val_acc: 0.5853\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.1874 - acc: 0.6411 - val_loss: 1.1999 - val_acc: 0.6147\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.1383 - acc: 0.6556 - val_loss: 1.1552 - val_acc: 0.6267\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.0924 - acc: 0.6720 - val_loss: 1.1128 - val_acc: 0.6400\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.0498 - acc: 0.6873 - val_loss: 1.0761 - val_acc: 0.6447\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.0107 - acc: 0.6981 - val_loss: 1.0440 - val_acc: 0.6600\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9742 - acc: 0.7083 - val_loss: 1.0106 - val_acc: 0.6673\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.9410 - acc: 0.7181 - val_loss: 0.9865 - val_acc: 0.6720\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9109 - acc: 0.7253 - val_loss: 0.9555 - val_acc: 0.6800\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8834 - acc: 0.7283 - val_loss: 0.9341 - val_acc: 0.6820\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.8583 - acc: 0.7360 - val_loss: 0.9102 - val_acc: 0.6853\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8347 - acc: 0.7392 - val_loss: 0.8932 - val_acc: 0.6873\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8135 - acc: 0.7424 - val_loss: 0.8731 - val_acc: 0.7000\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.7936 - acc: 0.7497 - val_loss: 0.8580 - val_acc: 0.6993\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.7755 - acc: 0.7523 - val_loss: 0.8457 - val_acc: 0.7027\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.7587 - acc: 0.7564 - val_loss: 0.8285 - val_acc: 0.7033\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.7428 - acc: 0.7600 - val_loss: 0.8181 - val_acc: 0.7047\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.7281 - acc: 0.7612 - val_loss: 0.8033 - val_acc: 0.7113\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.7141 - acc: 0.7673 - val_loss: 0.7964 - val_acc: 0.7107\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.7018 - acc: 0.7707 - val_loss: 0.7850 - val_acc: 0.7127\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.6889 - acc: 0.7737 - val_loss: 0.7754 - val_acc: 0.7187\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.6779 - acc: 0.7736 - val_loss: 0.7655 - val_acc: 0.7167\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.6672 - acc: 0.7781 - val_loss: 0.7618 - val_acc: 0.7247\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.6572 - acc: 0.7820 - val_loss: 0.7542 - val_acc: 0.7140\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.6473 - acc: 0.7813 - val_loss: 0.7443 - val_acc: 0.7280\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.6385 - acc: 0.7835 - val_loss: 0.7407 - val_acc: 0.7227\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.6297 - acc: 0.7861 - val_loss: 0.7339 - val_acc: 0.7300\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.6208 - acc: 0.7891 - val_loss: 0.7306 - val_acc: 0.7287\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.6134 - acc: 0.7932 - val_loss: 0.7245 - val_acc: 0.7260\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.6054 - acc: 0.7941 - val_loss: 0.7223 - val_acc: 0.7280\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5978 - acc: 0.7988 - val_loss: 0.7154 - val_acc: 0.7293\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.5904 - acc: 0.7988 - val_loss: 0.7152 - val_acc: 0.7247\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.5837 - acc: 0.8035 - val_loss: 0.7096 - val_acc: 0.7227\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.5769 - acc: 0.8052 - val_loss: 0.7031 - val_acc: 0.7347\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.5707 - acc: 0.8072 - val_loss: 0.6987 - val_acc: 0.7340\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5645 - acc: 0.8092 - val_loss: 0.6959 - val_acc: 0.7353\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5584 - acc: 0.8108 - val_loss: 0.6920 - val_acc: 0.7353\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.5520 - acc: 0.8120 - val_loss: 0.6898 - val_acc: 0.7380\n",
      "Epoch 56/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.5466 - acc: 0.8153 - val_loss: 0.6890 - val_acc: 0.7347\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.5407 - acc: 0.8165 - val_loss: 0.6868 - val_acc: 0.7340\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5362 - acc: 0.8197 - val_loss: 0.6815 - val_acc: 0.7407\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5300 - acc: 0.8220 - val_loss: 0.6885 - val_acc: 0.7313\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.5252 - acc: 0.8232 - val_loss: 0.6773 - val_acc: 0.7360\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.5196 - acc: 0.8251 - val_loss: 0.6740 - val_acc: 0.7433\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5150 - acc: 0.8275 - val_loss: 0.6765 - val_acc: 0.7427\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5100 - acc: 0.8292 - val_loss: 0.6676 - val_acc: 0.7447\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5050 - acc: 0.8317 - val_loss: 0.6685 - val_acc: 0.7373\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5004 - acc: 0.8347 - val_loss: 0.6704 - val_acc: 0.7433\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.4959 - acc: 0.8360 - val_loss: 0.6661 - val_acc: 0.7440\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4914 - acc: 0.8381 - val_loss: 0.6670 - val_acc: 0.7420\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.4866 - acc: 0.8387 - val_loss: 0.6591 - val_acc: 0.7467\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4825 - acc: 0.8412 - val_loss: 0.6591 - val_acc: 0.7460\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.4782 - acc: 0.8417 - val_loss: 0.6622 - val_acc: 0.7460\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4740 - acc: 0.8452 - val_loss: 0.6577 - val_acc: 0.7433\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4702 - acc: 0.8448 - val_loss: 0.6540 - val_acc: 0.7447\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.4659 - acc: 0.8476 - val_loss: 0.6559 - val_acc: 0.7433\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.4617 - acc: 0.8475 - val_loss: 0.6518 - val_acc: 0.7453\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4578 - acc: 0.8489 - val_loss: 0.6510 - val_acc: 0.7440\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.4536 - acc: 0.8513 - val_loss: 0.6546 - val_acc: 0.7487\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 0.4500 - acc: 0.8533 - val_loss: 0.6504 - val_acc: 0.7507\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.4464 - acc: 0.8539 - val_loss: 0.6492 - val_acc: 0.7460\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.4421 - acc: 0.8548 - val_loss: 0.6511 - val_acc: 0.7453\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 0.4382 - acc: 0.8568 - val_loss: 0.6544 - val_acc: 0.7493\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.4354 - acc: 0.8581 - val_loss: 0.6484 - val_acc: 0.7447\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.4320 - acc: 0.8576 - val_loss: 0.6468 - val_acc: 0.7473\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.4280 - acc: 0.8599 - val_loss: 0.6485 - val_acc: 0.7493\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.4244 - acc: 0.8619 - val_loss: 0.6443 - val_acc: 0.7467\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4208 - acc: 0.8607 - val_loss: 0.6453 - val_acc: 0.7520\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.4179 - acc: 0.8637 - val_loss: 0.6498 - val_acc: 0.7500\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.4143 - acc: 0.8643 - val_loss: 0.6430 - val_acc: 0.7487\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.4106 - acc: 0.8665 - val_loss: 0.6425 - val_acc: 0.7533\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.4074 - acc: 0.8693 - val_loss: 0.6439 - val_acc: 0.7500\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.4041 - acc: 0.8687 - val_loss: 0.6435 - val_acc: 0.7507\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.4009 - acc: 0.8712 - val_loss: 0.6444 - val_acc: 0.7527\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.3977 - acc: 0.8741 - val_loss: 0.6474 - val_acc: 0.7533\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.3945 - acc: 0.8739 - val_loss: 0.6463 - val_acc: 0.7533\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.3917 - acc: 0.8765 - val_loss: 0.6485 - val_acc: 0.7540\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.3887 - acc: 0.8756 - val_loss: 0.6394 - val_acc: 0.7513\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.3854 - acc: 0.8776 - val_loss: 0.6443 - val_acc: 0.7587\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.3820 - acc: 0.8793 - val_loss: 0.6430 - val_acc: 0.7527\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.3796 - acc: 0.8784 - val_loss: 0.6432 - val_acc: 0.7540\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.3764 - acc: 0.8809 - val_loss: 0.6409 - val_acc: 0.7540\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.3731 - acc: 0.8813 - val_loss: 0.6394 - val_acc: 0.7527\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.3708 - acc: 0.8829 - val_loss: 0.6450 - val_acc: 0.7573\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.3677 - acc: 0.8847 - val_loss: 0.6452 - val_acc: 0.7480\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.3650 - acc: 0.8847 - val_loss: 0.6418 - val_acc: 0.7533\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.3625 - acc: 0.8864 - val_loss: 0.6445 - val_acc: 0.7493\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.3591 - acc: 0.8872 - val_loss: 0.6459 - val_acc: 0.7573\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.3568 - acc: 0.8887 - val_loss: 0.6463 - val_acc: 0.7473\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.3541 - acc: 0.8892 - val_loss: 0.6432 - val_acc: 0.7587\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.3513 - acc: 0.8896 - val_loss: 0.6409 - val_acc: 0.7547\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.3485 - acc: 0.8928 - val_loss: 0.6416 - val_acc: 0.7553\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.3459 - acc: 0.8917 - val_loss: 0.6422 - val_acc: 0.7527\n",
      "Epoch 111/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.3434 - acc: 0.8932 - val_loss: 0.6401 - val_acc: 0.7560\n",
      "Epoch 112/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.3408 - acc: 0.8944 - val_loss: 0.6418 - val_acc: 0.7540\n",
      "Epoch 113/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.3378 - acc: 0.8964 - val_loss: 0.6406 - val_acc: 0.7573\n",
      "Epoch 114/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.3359 - acc: 0.8969 - val_loss: 0.6414 - val_acc: 0.7527\n",
      "Epoch 115/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.3330 - acc: 0.8979 - val_loss: 0.6456 - val_acc: 0.7547\n",
      "Epoch 116/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.3305 - acc: 0.8985 - val_loss: 0.6466 - val_acc: 0.7533\n",
      "Epoch 117/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.3280 - acc: 0.9007 - val_loss: 0.6416 - val_acc: 0.7560\n",
      "Epoch 118/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.3256 - acc: 0.9009 - val_loss: 0.6470 - val_acc: 0.7567\n",
      "Epoch 119/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.3233 - acc: 0.9000 - val_loss: 0.6460 - val_acc: 0.7533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.3210 - acc: 0.9021 - val_loss: 0.6497 - val_acc: 0.7567\n",
      "Epoch 121/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.3185 - acc: 0.9015 - val_loss: 0.6470 - val_acc: 0.7540\n",
      "Epoch 122/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.3164 - acc: 0.9041 - val_loss: 0.6472 - val_acc: 0.7560\n",
      "Epoch 123/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.3136 - acc: 0.9051 - val_loss: 0.6464 - val_acc: 0.7573\n",
      "Epoch 124/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.3114 - acc: 0.9069 - val_loss: 0.6467 - val_acc: 0.7553\n",
      "Epoch 125/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.3089 - acc: 0.9072 - val_loss: 0.6549 - val_acc: 0.7553\n",
      "Epoch 126/150\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.3068 - acc: 0.9084 - val_loss: 0.6539 - val_acc: 0.7593\n",
      "Epoch 127/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.3045 - acc: 0.9067 - val_loss: 0.6506 - val_acc: 0.7580\n",
      "Epoch 128/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.3027 - acc: 0.9108 - val_loss: 0.6545 - val_acc: 0.7587\n",
      "Epoch 129/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.3001 - acc: 0.9107 - val_loss: 0.6502 - val_acc: 0.7580\n",
      "Epoch 130/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.2977 - acc: 0.9115 - val_loss: 0.6526 - val_acc: 0.7567\n",
      "Epoch 131/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.2956 - acc: 0.9121 - val_loss: 0.6519 - val_acc: 0.7567\n",
      "Epoch 132/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.2936 - acc: 0.9141 - val_loss: 0.6511 - val_acc: 0.7600\n",
      "Epoch 133/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.2915 - acc: 0.9132 - val_loss: 0.6545 - val_acc: 0.7580\n",
      "Epoch 134/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.2894 - acc: 0.9160 - val_loss: 0.6549 - val_acc: 0.7627\n",
      "Epoch 135/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.2873 - acc: 0.9159 - val_loss: 0.6543 - val_acc: 0.7600\n",
      "Epoch 136/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.2850 - acc: 0.9165 - val_loss: 0.6555 - val_acc: 0.7600\n",
      "Epoch 137/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.2831 - acc: 0.9171 - val_loss: 0.6581 - val_acc: 0.7613\n",
      "Epoch 138/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.2807 - acc: 0.9191 - val_loss: 0.6597 - val_acc: 0.7627\n",
      "Epoch 139/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.2791 - acc: 0.9185 - val_loss: 0.6587 - val_acc: 0.7613\n",
      "Epoch 140/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.2773 - acc: 0.9193 - val_loss: 0.6566 - val_acc: 0.7573\n",
      "Epoch 141/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.2750 - acc: 0.9204 - val_loss: 0.6589 - val_acc: 0.7620\n",
      "Epoch 142/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.2728 - acc: 0.9213 - val_loss: 0.6669 - val_acc: 0.7627\n",
      "Epoch 143/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.2711 - acc: 0.9211 - val_loss: 0.6668 - val_acc: 0.7600\n",
      "Epoch 144/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.2694 - acc: 0.9224 - val_loss: 0.6607 - val_acc: 0.7613\n",
      "Epoch 145/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.2670 - acc: 0.9233 - val_loss: 0.6626 - val_acc: 0.7573\n",
      "Epoch 146/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.2654 - acc: 0.9240 - val_loss: 0.6729 - val_acc: 0.7627\n",
      "Epoch 147/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.2632 - acc: 0.9256 - val_loss: 0.6685 - val_acc: 0.7593\n",
      "Epoch 148/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.2614 - acc: 0.9272 - val_loss: 0.6674 - val_acc: 0.7647\n",
      "Epoch 149/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.2601 - acc: 0.9280 - val_loss: 0.6688 - val_acc: 0.7573\n",
      "Epoch 150/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.2578 - acc: 0.9277 - val_loss: 0.6665 - val_acc: 0.7607\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "baseline_model_val = baseline_model.fit(X_train_tokens, y_train_lb, epochs=150, batch_size=256, validation_data=(X_test_tokens, y_test_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "The attribute `.history` (stored as a dictionary) contains four entries now: one per metric that was being monitored during training and validation. Print the keys of this dictionary for confirmation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the history attribute and store the dictionary\n",
    "baseline_model_val_dict = baseline_model_val.history\n",
    "\n",
    "# Print the keys\n",
    "baseline_model_val_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the training data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 52us/step\n",
      "----------\n",
      "Training Loss: 0.255 \n",
      "Training Accuracy: 0.929\n"
     ]
    }
   ],
   "source": [
    "results_train = baseline_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print('----------')\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 55us/step\n",
      "----------\n",
      "Test Loss: 0.666 \n",
      "Test Accuracy: 0.761\n"
     ]
    }
   ],
   "source": [
    "results_test = baseline_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print('----------')\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results \n",
    "\n",
    "Plot the loss versus the number of epochs. Be sure to include the training and the validation loss in the same plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss vs number of epochs with train and validation sets\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = fig.gca()\n",
    "ax.scatter(range(1,151), baseline_model_val_dict['loss']);\n",
    "ax.scatter(range(1,151), baseline_model_val_dict['val_loss']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a second plot comparing training and validation accuracy to the number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEvCAYAAAB2Xan3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3df5TddX3n8ed7JhMygZoAiav5gdAelm1EFJuiK5zdrj8KVE2i7UFQt7irzWlXilAbhLUHafYPEbbFH4ttaUp1+wtTijFabOqCPW3YqgyN8sumRmxlJloDGlxlMJPkvX/ce8Odm++duXfmznzvvfN8nJOTud/vd+58vnyH+8rnd2QmkiSpPANlF0CSpIXOMJYkqWSGsSRJJTOMJUkqmWEsSVLJDGNJkkq2qKwfvGLFijz99NPL+vGSJM2rBx544InMXFl0rrQwPv300xkZGSnrx0uSNK8i4l+anbOZWpKkkhnGkiSVzDCWJKlkhrEkSSUzjCVJKplhLElSyQxjSZJKZhhLklQyw1iSpJIZxpIklcwwliSpZKWtTS1JUhl27Bnj5l172X9wnGXDQ0TA956eYDCCI5msXj7MlgvPYtO5q+etTIaxJKmv1MJ27OD4sYBdXhe6AWT12oPjE8e+70hWjo4dHOe6ux4CmLdANowlSV2pqAZ78OmJwtpss7CtBWx96ObxP+o44xNHuHnXXsNYktSfpqq51sL20OEjPD1x9Nj31IdpUW223bBtxf6D4x16p+kZxpKkWZuuH7admmv912VatXx43n6WYSxJKtROM/F0/bBzUXOdS8NDg2y58Kx5+3mGsSQtIJ0I2KKw7YWArVe7t+WOppYkzaXG4G23H7bXArZeLWyL+qRXlRC202kpjCPiIuBDwCCwLTNvbDj/AuB2YCXwXeCtmTna4bJK0oJVNOipvgZXdL5ZzbYXLR0a4IShwWlHU3dr2E4nMqf+t09EDAL/BLwGGAXuBy7LzEfrrvlz4DOZ+fGIeCXwXzLzP0/1vuvXr8+RkZHZll+S+kI7c2Pr1Y43O9+tpqq5LuvxYG0mIh7IzPVF51qpGZ8H7MvMx6pvdgewEXi07pp1wNXVrz8P7Jh5cSWpfzUbdTzTubE5zfn5NFU/bK/XXOdaK2G8Gni87vUo8LKGa74C/DyVpuw3AD8WEadm5pMdKaUk9YipBkhN1WfbDWFapDFgmzUTlzHoqZ+0EsZRcKzx9+bXgf8VEW8D/hYYAw4f90YRm4HNAKeddlpbBZWkskw3ArndhSq6xXT9sAbs/GkljEeBtXWv1wD76y/IzP3AGwEi4iTg5zPzqcY3yszbgNug0mc8wzJLUkfNtDbb7WELxTVbm4m7TythfD9wZkScQaXGeynw5voLImIF8N3MPApcR2VktSR1hU6EbTdoHPTUOGir8bw1294xbRhn5uGIuALYRWVq0+2Z+UhEbAVGMnMn8DPA+yMiqTRTv3MOyyxJk/Rr2E5Xm62/b2u7vW3aqU1zxalNkmZiuoUsekl9n61h2v9mO7VJkubNdBsO9NJCFkUDpAxeFTGMJZWmnVWjumWJxmYBa9hqNgxjSfOqPoCLFrro1rA1YDWXDGNJs1Y0kAiYdqWpMoLXsFU3MowlzUizGu7YwXGu+sSXJ107nytNGbbqRYaxpELtTBea7xquC1mo3xjG0gLVzXNzu23jd2muGcbSAjDTTebng6tGSYax1Hd6YZP5WnkMXqnCMJZ6VDv74s5Hn+5Um9y70pQ0NcNY6gHtNDOXMV3o5KVDvO/1L2TTuatdL1maAcNY6gJFTcvLm9R2y2hmbme60KZzVxu+UpsMY6kk061E5dxcaeEwjKV51CyA57NP17m5UvcxjKU5Ml0/71wGsNOFpN5iGEsdUPZ0IkcrS73NMJbaUOZ0IpuZpf5lGEst2LFnjBt2PtJ0papOBG9j07KhKy0chrHURLPBVp3kSlSSwDCWgOn7fOciiOsXypC0sBnGWlDmu8/Xfl5JrTCMtSCU0edr07OkVrUUxhFxEfAhYBDYlpk3Npw/Dfg4sLx6zbWZeXeHyyq1Za77fJ1OJKlTpg3jiBgEbgVeA4wC90fEzsx8tO6y3wC2Z+bvRMQ64G7g9Dkor3ScVpqeO1nztcYrqdNaqRmfB+zLzMcAIuIOYCNQH8YJPKf69TJgfycLKRWZz6ZnA1jSXGoljFcDj9e9HgVe1nDNDcBfR8SvAicCr+5I6aQGc9n0bJ+vpLK0EsZRcKzxM/Ay4GOZ+VsR8e+BP4qIszPzaP1FEbEZ2Axw2mmnzaS8WoDmanMF+3wldYtWwngUWFv3eg3HN0O/HbgIIDP/PiKWACuA79RflJm3AbcBrF+/vow90NVDipqhZ/NLY5OzpG7VShjfD5wZEWcAY8ClwJsbrvkm8CrgYxHxk8AS4EAnC6r+U7TQxvImA7BmygCW1AumDePMPBwRVwC7qExbuj0zH4mIrcBIZu4E3g38fkRcTeWz722Zac1Xx2nW5FxbaGO2tWCbniX1opbmGVfnDN/dcOz6uq8fBc7vbNHUb3bsGeO6ux5ifOII4GhnSapxBS7NmaJm6E4wgCX1G8NYHTVdM/RsubmCpH5kGGvW5mrqEVgLlrQwGMaaldn2AzcutOHuRlIfeXA73LMVnhqFZWvgVdfDOZfM7Nr688MnV46Nf2/q9232nu2Ua55EWYOe169fnyMjI6X8bM1c4zrQ339mgqMz/BWytquOKevDtQs/1Ges6F5g5mF65s/CV/4UJsbrLqr+83v4lMrL8e9CDEIeefZc47XL1jZ5rwZDJ8KiE54N6Kl+fuPPGhqGF78ZvvbXc/osI+KBzFxfeM4w1nQ6vQTl8NAg73/jiwxhdcaD2+HTV07+0B0ahtd/ePoP01bDtFlQtfNzOxZ2jz8bYMvWTl3bq3//qWqTRf8NC7UTpj2u1d+hNhjGmpGiFbDa5XrPOs6MmiPrPvSPBUE1VA79sHK+SFFo1B9rpYZUVMMaGoZFw81/bis/q/gbK9e09f1NanutOFabbHIfC92ytXD1wx17O8NYLetELdhBVz2inVBs5/xUNTgoqIE1BFDpNayyf766R8ANBzv3boaxWtE4GGsmBiP4rUtebAB3QrMBK60OXpnqfT/7noLa0DR9dLVmO5j6+6etwUk9wpqxynD+jfcydnC6PqPm7AumvQCF5v15rQxYqVc/eGXKpt1Wm0unYqhqrrTY5D58Chz+EUz8sAM/qwn7jDXf6pumW1H7FV6Q05CmarpteRAMMDAEEXDk0NyWV5q1dvqkWxytXPQPxsbBaEWtL40B2Wx8QaujpaH4/9nhU+DiDziaWnNvpn3Dfb8CVrthW//hcMvZlX5SlaykmvvQcOstGZPMIOza6l+vGwE9XW1yqik+0w2sm25k90yCbabv08n5zR1kGOuYdkdI981grKJBRfWjcodPbvJBVfdB9sxByKPHv3ftQ+iuX5rru+hD0/Qvz3Y09GxHYzeb+9qo9jsw1e/YdNOZpvsdbXUQXbP3L/qe2Y4/UFsMYwHtD9AqPYA7+a/rVpuPZ8x+1MmmqcHVDwabau7sdDrxOzJVi8ex8k0zzanDfYvqT4bxAtdunzBUgvi+a185h6Wq0+qCCjC5L2e6RRBq+qH5uKVafDvqRk5Pqk09znHBWdi/3ez7ZzhNqmxd2qyp/mIYL0CzmS88p6OiW1kyb7oFFVqdQnOs+Xhzk+vmwfApzwZos2bu2nVFAdvqik6FI7enaJptN2zAAJJmyTBeYGYyX3he+oYLm4vnunm3xObjxjmKrSzbaK1L6ltThbG7NvWZHXvGePf2r7S1f/CcjZBuDJZDPyzot53roJyr929hjmKtRllTC9WpwvacSwxfaQEyjPtIrUbcahDPay24m/psm42mrn0940U5GprHi0LVsJVUwDDuIzfv2ttS03TH+oSnnIrRrQvPB7yvjbJNFZynvdwmZUkdYRj3gVZGS3e8T7ix5pvVfwTMRQgPnwKLTywe6dvuIgjL1nSuXNZyJXWIYdzjWhms1dHNG+prw/NhaHjysnQt7yRUENxF/biS1AVaGk0dERcBHwIGgW2ZeWPD+VuA/1R9uRR4bmYun+o9HU3dGdNt7jCrJumiZuhOjU4+9n4NjtWCO9D068hkSV1kVqOpI2IQuBV4DTAK3B8ROzPz0do1mXl13fW/Cpw761JrSq00TbfcJN3KYuvHgrMDQVxbsrBofnEnF2e3GVlSj2ilmfo8YF9mPgYQEXcAG4FHm1x/GfC+zhRPRVppmm55Ba3Gvt9Jfb4dDN6ihecdACVJQGthvBqo7yAcBV5WdGFEvAA4A7h39kVTM9ONmh4eGmTLhWe19mb3bO3Mms0zWenJmqskAa2FcRQca1ZluhS4M7OoMxAiYjOwGeC0005rqYA63v5ONE3XPDU6u8K4SL4kzVorYTwKrK17vQbY3+TaS4F3NnujzLwNuA0qA7haLKPq7NgzxkBE4cIeLTVNNw7KmlFTdAuLW0iSWtZKGN8PnBkRZwBjVAL3zY0XRcRZwMnA33e0hDpmqhW2pmyabjbdp7gBo0HDPF4DWJI6btowzszDEXEFsIvK1KbbM/ORiNgKjGTmzuqllwF3ZFk7TywAzfqKByOOn77UdL7tNI+nnT5fSVJHtLToR2beDdzdcOz6htc3dK5YKtKsr/ho5vFBPGl3oFb/fRTwnm/MqoySpPa5AlcPqM0pbhapq5YPP/viwe3wyV9usQm6QSeXipQktcww7nLTzSme1FdcqxHPJIhdKlKSSmMYd7mp5hQfm8Y0eB/c0s560Q7KkqRuYhh3uWb9xAGVaUzH9Q8343QkSepWhnGXW7V8uHD96ctP+hLc8p7WasMxCG/4XQNYkrrUQNkF0NS2XHgWw0ODk479wuL/y2/k77YWxEPDBrEkdTlrxl2qNoJ6/8Fxlg0PsWRogINPT7Bq+TBb4y9YNP7M9G9ik7Qk9QTDuAs1jqA+OD7B8NAgt7zpJZX5xDd8e+o3cL1oSeopNlN3oaIR1OMTR7h5197Ki6nmAy9baxBLUo+xZtyFmo2g3n9wvDJ6+tAPjz9pbViSepZh3GWKdmXaMLCbaxZtZ9XAE3BX/TrTVcOnwMUfMIglqUcZxl2kaFemDQO7uXFoG0vjUPVIwaKYi080iCWph9ln3EWK+oqvWbS9LoibeGp0DkslSZprhnEXKeorXhVPTP+NbvAgST3NMO4ik3ZfqtqfK6b+Jjd4kKSeZxh3gR17xjj/xnsZOzhOVI9tGNjN7sVXsiqeKOglrl7lNCZJ6gsO4CpZ4wIfCWwc2M37Jw3aAjd6kKT+ZRiXrGjQ1pbCQVvVIL764fkrnCRpXthMXbLGQVsbBnazutmgLUdNS1JfMoxLVj9oqzanOKLJxY6alqS+ZBiXrH6LxCnnFDtqWpL6ln3GJSnaInHVkSnmFDtqWpL6Vks144i4KCL2RsS+iLi2yTWXRMSjEfFIRPxpZ4vZX2ojqMcOjpNUtkh8ZuIozyx9fvE3LFtrEEtSH5s2jCNiELgVuBhYB1wWEesarjkTuA44PzNfCFw1B2XtG822SLxp4k2V5uh6Nk9LUt9rpWZ8HrAvMx/LzEPAHcDGhmt+Cbg1M78HkJnf6Wwx+0uzLRI//oPzKs3Ry9YC4aIekrRAtNJnvBp4vO71KPCyhmv+LUBE3AcMAjdk5l91pIR9aNXyYcaK1qFePgznvNbwlaQFppWacdFEm8YVGhcBZwI/A1wGbIuI5ce9UcTmiBiJiJEDBw60W9a+UT+CumZ4aJAtF55VUokkSWVqJYxHgbV1r9cA+wuu+VRmTmTmN4C9VMJ5ksy8LTPXZ+b6lStXzrTMPW/Tuat5/xtfxOrlwwTwtpO+xAMnXcWmT70QbjkbHtxedhElSfOolWbq+4EzI+IMYAy4FHhzwzU7qNSIPxYRK6g0Wz/WyYL2m03nrmbTuasrwfvp34PxarP1U4/Dp6+sfG1ztSQtCNOGcWYejogrgF1U+oNvz8xHImIrMJKZO6vnfjYiHgWOAFsy88m5LHivqp9fvGr5MJ+L61k60dB/PDEO92w1jCVpgWhp0Y/MvBu4u+HY9XVfJ/Br1T9qonGHprGD4yw54dvFvfKuQy1JC4bLYc6j+vnFtf2Ko2C3YsB1qCVpAXE5zHlUm19c2xDCdaglSWDNeF7VdmiackMIF/qQpAXHMJ5HtfnFq5rtV0zA1Q8bxJK0wNhMPY82nbsagO98aiXPo2DRE/uJJWlBMoznQeN0pg++dAvPe+h9lSlMNfYTS9KCZTP1HGvcLnHs4Di/eP8LuP9Fv+mGEJIkwJrxnGu2XeJVj57Jfdc+XFKpJEndxJrxHGvcLrE2v/jvxt/gOtSSJMAwnnO16Uzw7PziNQNPMBA8uw61gSxJC5phPMfqt0ssnF9cW4dakrRg2Wc8x2rTmW7etZdV403mF7sOtSQtaNaM58Gmwfu474QrK03TRZxfLEkLmjXjOVKbW7z++5/jxsV/wDA/Kr7Q+cWStOAZxnOgfqvETyze3jyIl62tBLHziyVpQTOM50D93OJp16GWJC149hnPgfq5xftzRfFF9hNLkqoM4zlQP7f4psOX8HQunnyB/cSSpDo2U8+BLReexe5PfpSruINV8QTfy5N4hhM4OX5ALFtjP7EkaRLDeA5sGryP1w1tY9GRZwA4NX7A4cElxMbbDGFJ0nFspu6wHXvG+PZd//1YENcsOvKMK21JkgoZxh1Um9L03DxQfIErbUmSCrQUxhFxUUTsjYh9EXFtwfm3RcSBiPhy9c87Ol/U7leb0uQIaklSO6YN44gYBG4FLgbWAZdFxLqCSz+RmS+p/tnW4XL2hNqUJkdQS5La0UrN+DxgX2Y+lpmHgDuAjXNbrN60avkwGwZ2c82i7SzhEIdzgEz4Nivh9R928JYkqVArYbwaeLzu9Wj1WKOfj4gHI+LOiFjbkdL1mA+u+xofqNuveFEc5RkW8/hLtxjEkqSmWgnjor2GsuH1p4HTM/Mc4P8AHy98o4jNETESESMHDjQZ5NTDfvrrH2G4Yb/i4TjET3/9IyWVSJLUC1oJ41Ggvqa7Bthff0FmPpmZtd0Qfh/4qaI3yszbMnN9Zq5fuXLlTMrb3ZqNlnYUtSRpCq2E8f3AmRFxRkQsBi4FdtZfEBHPr3u5Afhq54rY/XbsGeP8G+9l9OipxRc4ilqSNIVpwzgzDwNXALuohOz2zHwkIrZGxIbqZVdGxCMR8RXgSuBtc1XgblObWzx2cNxR1JKkGYnMxu7f+bF+/focGRkp5Wd30vk33stY3S5NtdHUqwaeZMB1qCVJVRHxQGauLzrn2tSzVL9dIsDOoxew89AFBPCNG15bTqEkST3FMJ6lVcuH+anvf65SG44n2J8ruOnwJTzwnNeUXTRJUo8wjGfpg+u+xtkPbDs2pWlNPMEHhrbx8LrTgVeWWjZJUm9wo4gZqo2gfv7ITc4tliTNijXjGaiNoB6fOMKqE54ovsi5xZKkFlkznoHa7kyAOzRJkmbNMJ6B+hHUzi2WJM2WYTwDq5YPH/t659ELuHbiHYweXcFRApatdYcmSVJb7DOegS0XnsXuT36Uq7jj2HSmD3IpF2z8b2w6t2hDK0mSmjOMZ2DT4H28bmgbi448A1SmM904uI1Fgy8GrBFLktpjM/VM3LP1WBDXLDryDNyztaQCSZJ6mWE8E26VKEnqIMN4JppNW3I6kyRpBgzjNtRW3XrXgdczzgmTTzqdSZI0Qw7gatGOPWPs/uRH+QR3sGroCb539CTGYzEnxw8It0qUJM2CNeMWffkvb2Nr3MaagScYCDh14Acs4Uf85qJ3wdUPG8SSpBkzjFv0jkN/zNKGDSGWxiHeceiPSyqRJKlfGMYtWjXwZFvHJUlqlWHcomeGn9fWcUmSWmUYt2jpxVs5PLhk0rHDg0tYerELfUiSZscwbtU5l7Bo40cqG0FUN4RYtPEjDtySJM2aU5tasGPPGDfv2sv+gyeyavmH2bLxLDeEkCR1TEs144i4KCL2RsS+iLh2iut+ISIyItZ3rojl2rFnjOvueoixg+MkMHZwnOvueogde8bKLpokqU9MG8YRMQjcClwMrAMui4h1Bdf9GHAl8MVOF7JMN+/ay/jEkUnHxieOcPOuvSWVSJLUb1qpGZ8H7MvMxzLzEHAHsLHguv8B3AQ8U3CuZ+0/OM6Ggd3sXnwlj53wZnYvvpINA7vZf3C87KJJkvpEK2G8Gni87vVo9dgxEXEusDYzP9PBsnWFy0/6EjcObTu28taagSe4cWgbl5/0pbKLJknqE62EcRQcy2MnIwaAW4B3T/tGEZsjYiQiRg4cONB6KUt0zdAnClfeumboEyWVSJLUb1oJ41Fgbd3rNcD+utc/BpwN/E1E/DPwcmBn0SCuzLwtM9dn5vqVK1fOvNTzaOn4t9s6LklSu1oJ4/uBMyPijIhYDFwK7KydzMynMnNFZp6emacDXwA2ZObInJR4vrl3sSRpjk0bxpl5GLgC2AV8FdiemY9ExNaI2DDXBSyLexdLkuZLS4t+ZObdwN0NxwrTKDN/ZvbFKldtbvH4xBHGuIA8BO8Z2s6qeNK9iyVJHecKXAUa5xbvPHoBO390AauXD3Pf1a8ssWSSpH5kGBeozS2+ZtF2VsUT7M8V3HT4Ej598IKyiyZJ6kOGcYHLT/oS10xsOzalaU1U5hafMrQYeG25hZMk9R13bSrg3GJJ0nwyjAs4t1iSNJ8M4yLOLZYkzSPDuN6D2+GWs+GpxzluFVDnFkuS5ogDuGoe3M7hT/0qi47UNp1KkmokL1vr3GJJ0pwxjKue/uz1LD0yeffHAJ4efj5Lr364nEJJkhYEm6mrljQZnNXsuCRJnWIYV+0/empbxyVJ6hTDuGrb4rfydC6edOzpXMy2xW8tqUSSpIXCMK56yWs3c31uZvToCo5mMHp0BdfnZl7y2s1lF02S1OccwAXw4HY2/c1WNg6M8q+s4OpDv8LIc17DlgvPYtO5q8sunSSpzxnGD26HT18JE+ME8DwO8KET/xB+7lw4xx2aJElzz2bqe7bCxPjkYxPjleOSJM0Dw/ip0faOS5LUYYax61BLkkpmGL/qeg4PLpl06PDgEtehliTNmwUfxjuOnM+1E++YNKXp2ol3sOPI+WUXTZK0QCz40dQ379rL2KFXcCevmHT873ftdVqTJGleLPia8f6D420dlySp01oK44i4KCL2RsS+iLi24PwvR8RDEfHliNgdEes6X9QOq+5d/PUlb2H34ivZMLB70ulVy4dLKpgkaaGZNowjYhC4FbgYWAdcVhC2f5qZL8rMlwA3Ab/d8ZJ2Um2hj6ceZ4BkzcAT3Di07VggDw8NsuXCs0oupCRpoWilZnwesC8zH8vMQ8AdwMb6CzLz+3UvTwSyc0WcAwULfSyNQ1yzaDurlw/z/je+yP5iSdK8aWUA12rg8brXo8DLGi+KiHcCvwYsBrp7HckmC3qsGXiS+67t7qJLkvpPKzXjKDh2XM03M2/NzJ8A3gP8RuEbRWyOiJGIGDlw4EB7Je2gp4ef19ZxSZLmUithPAqsrXu9Btg/xfV3AJuKTmTmbZm5PjPXr1y5svVSdthNE28q3Lv4pok3lVQiSdJC1koY3w+cGRFnRMRi4FJgZ/0FEXFm3cvXAl/rXBE7qDqC+vqJDzKei/lunjRpoY+P/+C8sksoSVqApu0zzszDEXEFsAsYBG7PzEciYiswkpk7gSsi4tXABPA94PK5LPSM1G2VOBBwavyAp3MxV038CjuPXgDAaqczSZJK0NIKXJl5N3B3w7Hr675+V4fL1XlTjKDeeegCpzNJkkqzcJbDbDKCelU8yerlw2y58CynM0mSSrFwwnjZGnjq8eMODyxfw31XO51JklSehbM2tVslSpK61MII4we38/Rnr2fg8DMczgEycatESVLX6P8wro6iXjr+LQYCFsVRxlnMTYcv4c5Dr+DmXXvLLqEkaYHr/zCeYhQ1uFWiJKl8/R/GU4yiBrdKlCSVr//DeNmawsP781TnFkuSukL/h/GrroehybXfp3Mx2xa/1a0SJUldof/nGZ9zSeXve7ZWmqyXrWHpq67nhtpxSZJK1v9hDOw4cj43/+jD7H9mnFVLhtly5KzibaUkSSpB34fxjj1jXHfXQ4xPHAFg7OA41931EIBN1JKkrtD3fcY379p7LIhrxieOOL9YktQ1+jeMq3sX/934G9i9+Eo2DOyedNr5xZKkbtGfzdQNexeviSe4cWgbTHBs72LnF0uSukV/1oynWXXL+cWSpG7SnzVj9y6WJPWQ/gxj9y6WJPWQ/mymLlh1i6Fh9y6WJHWl/gzjcy6B138Ylq0FovL36z/87GpckiR1kf5spoZK8Bq+kqQe0J81Y0mSeohhLElSyVoK44i4KCL2RsS+iLi24PyvRcSjEfFgRNwTES/ofFHbs2PPGOffeC9nXPuXnH/jvezYM1Z2kSRJKjRtGEfEIHArcDGwDrgsItY1XLYHWJ+Z5wB3Ajd1uqDtqG0OMXZwnOTZzSEMZElSN2qlZnwesC8zH8vMQ8AdwMb6CzLz85n5dPXlF4A1nS1me9wcQpLUS1oJ49VA/Qoao9Vjzbwd+GzRiYjYHBEjETFy4MCB1kvZpmabQLg5hCSpG7USxlFwLAsvjHgrsB64ueh8Zt6Wmeszc/3KlStbL2Wrqjs1fX3JWwp3anJzCElSN2plnvEosLbu9Rpgf+NFEfFq4L3Af8zMH3WmeG2o36kJWDMweacmN4eQJHWrVmrG9wNnRsQZEbEYuBTYWX9BRJwL/B6wITO/0/litmCKnZpWLx/m/W98kZtDSJK60rQ148w8HBFXALuAQeD2zHwkIrYCI5m5k0qz9EnAn0cEwDczc8Mclvt4TXZqWjPwJPdd6+YQkqTu1dJymJl5N3B3w7Hr675+dYfL1b4mOzWxrNSB3ZIkTat/VuBypyZJUo/qnzB2pyZJUo/qr12b3KlJktSD+qdmLElSjzKMJUkqWV81U+/YM8bNu/ay/+A4q5YPs+XCs5xbLEnqen0TxrWdmmobRNR2agIMZElSV+ubZmp3apIk9aq+CdI9puYAAAXSSURBVGN3apIk9aq+CeNmOzK5U5Mkqdv1TRhvufAshocGJx1zpyZJUi/omwFctUFajqaWJPWavgljqASy4StJ6jV900wtSVKvMowlSSqZYSxJUskMY0mSSmYYS5JUMsNYkqSSGcaSJJXMMJYkqWSGsSRJJTOMJUkqmWEsSVLJIjPL+cERB4B/6fDbrgCe6PB7lq0f7wm8r17Sj/cE3lcv6Zd7ekFmriw6UVoYz4WIGMnM9WWXo5P68Z7A++ol/XhP4H31kn68p0Y2U0uSVDLDWJKkkvVbGN9WdgHmQD/eE3hfvaQf7wm8r17Sj/c0SV/1GUuS1Iv6rWYsSVLP6YswjoiLImJvROyLiGvLLs9MRcTaiPh8RHw1Ih6JiHdVj58SEZ+LiK9V/z657LK2KyIGI2JPRHym+vqMiPhi9Z4+ERGLyy5juyJieUTcGRH/WH1m/75PntXV1d+/hyPizyJiSS8+r4i4PSK+ExEP1x0rfD5R8eHqZ8iDEfHS8kreXJN7urn6O/hgRHwyIpbXnbuuek97I+LCcko9vaL7qjv36xGREbGi+ronnlW7ej6MI2IQuBW4GFgHXBYR68ot1YwdBt6dmT8JvBx4Z/VergXuycwzgXuqr3vNu4Cv1r3+AHBL9Z6+B7y9lFLNzoeAv8rMfwe8mMr99fSziojVwJXA+sw8GxgELqU3n9fHgIsajjV7PhcDZ1b/bAZ+Z57K2K6Pcfw9fQ44OzPPAf4JuA6g+tlxKfDC6vd8tPp52Y0+xvH3RUSsBV4DfLPucK88q7b0fBgD5wH7MvOxzDwE3AFsLLlMM5KZ38rMf6h+/f+ofLivpnI/H69e9nFgUzklnJmIWAO8FthWfR3AK4E7q5f04j09B/gPwB8AZOahzDxIjz+rqkXAcEQsApYC36IHn1dm/i3w3YbDzZ7PRuB/Z8UXgOUR8fz5KWnriu4pM/86Mw9XX34BWFP9eiNwR2b+KDO/Aeyj8nnZdZo8K4BbgGuA+sFNPfGs2tUPYbwaeLzu9Wj1WE+LiNOBc4EvAv8mM78FlcAGnlteyWbkg1T+hzpafX0qcLDuA6QXn9mPAweAP6w2v2+LiBPp8WeVmWPA/6RSE/kW8BTwAL3/vGqaPZ9++Rz5r8Bnq1/39D1FxAZgLDO/0nCqp++rmX4I4yg41tNDxCPiJOAvgKsy8/tll2c2IuJ1wHcy84H6wwWX9tozWwS8FPidzDwX+CE91iRdpNqHuhE4A1gFnEilWbBRrz2v6fT872REvJdKV9ef1A4VXNYT9xQRS4H3AtcXnS441hP3NZV+CONRYG3d6zXA/pLKMmsRMUQliP8kM++qHv7XWjNM9e/vlFW+GTgf2BAR/0ylC+GVVGrKy6vNoNCbz2wUGM3ML1Zf30klnHv5WQG8GvhGZh7IzAngLuAV9P7zqmn2fHr6cyQiLgdeB7wln52v2sv39BNU/kH4lepnxxrgHyLiefT2fTXVD2F8P3BmdbTnYioDFnaWXKYZqfal/gHw1cz87bpTO4HLq19fDnxqvss2U5l5XWauyczTqTybezPzLcDngV+oXtZT9wSQmd8GHo+Is6qHXgU8Sg8/q6pvAi+PiKXV38faffX086rT7PnsBH6xOlL35cBTtebsbhcRFwHvATZk5tN1p3YCl0bECRFxBpUBT18qo4ztysyHMvO5mXl69bNjFHhp9f+7nn1WU8rMnv8D/ByVUYRfB95bdnlmcR8XUGlueRD4cvXPz1HpY70H+Fr171PKLusM7+9ngM9Uv/5xKh8M+4A/B04ou3wzuJ+XACPV57UDOLkfnhXwm8A/Ag8DfwSc0IvPC/gzKv3eE1Q+zN/e7PlQafq8tfoZ8hCV0eSl30OL97SPSh9q7TPjd+uuf2/1nvYCF5dd/nbuq+H8PwMreulZtfvHFbgkSSpZPzRTS5LU0wxjSZJKZhhLklQyw1iSpJIZxpIklcwwliSpZIaxJEklM4wlSSrZ/wewOz6A42KJngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy vs number of epochs with train and validation sets\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = fig.gca()\n",
    "ax.scatter(range(1,151), baseline_model_val_dict['acc']);\n",
    "ax.scatter(range(1,151), baseline_model_val_dict['val_acc']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice an interesting pattern here? Although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss don't necessarily do the same. After a certain point, validation accuracy keeps swinging, which means that you're probably **overfitting** the model to the training data when you train for many epochs past a certain dropoff point. Let's tackle this now. You will now specify an early stopping point when training your model. \n",
    "\n",
    "\n",
    "## Early Stopping\n",
    "\n",
    "Overfitting neural networks is something you **_want_** to avoid at all costs. However, it's not possible to know in advance how many *epochs* you need to train your model on, and running the model multiple times with varying number of *epochs* maybe helpful, but is a time-consuming process. \n",
    "\n",
    "We've defined a model with the same architecture as above. This time specify an early stopping point when training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "model_2 = models.Sequential()\n",
    "model_2.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "model_2.add(layers.Dense(25, activation='relu'))\n",
    "model_2.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model_2.compile(optimizer='SGD', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import `EarlyStopping` and `ModelCheckpoint` from `keras.callbacks` \n",
    "- Define a list, `early_stopping`: \n",
    "  - Monitor `'val_loss'` and continue training for 10 epochs before stopping \n",
    "  - Save the best model while monitoring `'val_loss'` \n",
    " \n",
    "> If you need help, consult [documentation](https://keras.io/callbacks/).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import EarlyStopping and ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define the callbacks\n",
    "early_stopping = [EarlyStopping(monitor='val_loss', patience=10), ModelCheckpoint('model.hdf5', save_best_only=True, monitor='val_loss')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train `model_2`. Make sure you set the `callbacks` argument to `early_stopping`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1500 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.3638 - acc: 0.8803 - val_loss: 0.6512 - val_acc: 0.7500\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.3609 - acc: 0.8825 - val_loss: 0.6491 - val_acc: 0.7480\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.3587 - acc: 0.8820 - val_loss: 0.6466 - val_acc: 0.7533\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.3563 - acc: 0.8835 - val_loss: 0.6474 - val_acc: 0.7493\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.3538 - acc: 0.8821 - val_loss: 0.6497 - val_acc: 0.7507\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.3514 - acc: 0.8845 - val_loss: 0.6480 - val_acc: 0.7527\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.3491 - acc: 0.8859 - val_loss: 0.6474 - val_acc: 0.7547\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.3467 - acc: 0.8879 - val_loss: 0.6526 - val_acc: 0.7493\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.3442 - acc: 0.8881 - val_loss: 0.6504 - val_acc: 0.7520\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.3417 - acc: 0.8892 - val_loss: 0.6499 - val_acc: 0.7480\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.3397 - acc: 0.8903 - val_loss: 0.6509 - val_acc: 0.7520\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.3373 - acc: 0.8929 - val_loss: 0.6497 - val_acc: 0.7587\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.3354 - acc: 0.8925 - val_loss: 0.6500 - val_acc: 0.7533\n"
     ]
    }
   ],
   "source": [
    "model_2_val =model_2.fit(X_train_tokens, y_train_lb, epochs=150, batch_size=256, validation_data=(X_test_tokens, y_test_lb), callbacks = early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best (saved) model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 50)                100050    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 182       \n",
      "=================================================================\n",
      "Total params: 101,507\n",
      "Trainable params: 101,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best (saved) model\n",
    "from keras.models import load_model\n",
    "saved_model = load_model('model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use this model to to calculate the training and test accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 50us/step\n",
      "Training Loss: 0.356 \n",
      "Training Accuracy: 0.885\n",
      "----------\n",
      "1500/1500 [==============================] - 0s 44us/step\n",
      "Test Loss: 0.647 \n",
      "Test Accuracy: 0.753\n"
     ]
    }
   ],
   "source": [
    "results_train = saved_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = saved_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicely done! Did you notice that the model didn't train for all 150 epochs? You reduced your training time. \n",
    "\n",
    "Now, take a look at how regularization techniques can further improve your model performance. \n",
    "\n",
    "## L2 Regularization \n",
    "\n",
    "First, take a look at L2 regularization. Keras makes L2 regularization easy. Simply add the `kernel_regularizer=keras.regularizers.l2(lambda_coeff)` parameter to any model layer. The `lambda_coeff` parameter determines the strength of the regularization you wish to perform. \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L2 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 2.5825 - acc: 0.1688 - val_loss: 2.5608 - val_acc: 0.2000\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 2.5427 - acc: 0.2169 - val_loss: 2.5275 - val_acc: 0.2410\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 2.5104 - acc: 0.2585 - val_loss: 2.4970 - val_acc: 0.2860\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 2.4790 - acc: 0.2951 - val_loss: 2.4648 - val_acc: 0.3090\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.4460 - acc: 0.3220 - val_loss: 2.4305 - val_acc: 0.3400\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 2.4103 - acc: 0.3536 - val_loss: 2.3935 - val_acc: 0.3730\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.3719 - acc: 0.3789 - val_loss: 2.3533 - val_acc: 0.3930\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.3302 - acc: 0.4019 - val_loss: 2.3099 - val_acc: 0.4170\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 2.2857 - acc: 0.4223 - val_loss: 2.2640 - val_acc: 0.4520\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 2.2384 - acc: 0.4473 - val_loss: 2.2151 - val_acc: 0.4680\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 2.1892 - acc: 0.4689 - val_loss: 2.1652 - val_acc: 0.4880\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 2.1386 - acc: 0.4904 - val_loss: 2.1149 - val_acc: 0.5090\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 2.0883 - acc: 0.5125 - val_loss: 2.0652 - val_acc: 0.5250\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 2.0383 - acc: 0.5385 - val_loss: 2.0159 - val_acc: 0.5520\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.9894 - acc: 0.5651 - val_loss: 1.9691 - val_acc: 0.5750\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.9420 - acc: 0.5827 - val_loss: 1.9244 - val_acc: 0.5960\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.8964 - acc: 0.6081 - val_loss: 1.8793 - val_acc: 0.6120\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.8527 - acc: 0.6247 - val_loss: 1.8394 - val_acc: 0.6280\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.8113 - acc: 0.6387 - val_loss: 1.7989 - val_acc: 0.6460\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.7710 - acc: 0.6532 - val_loss: 1.7630 - val_acc: 0.6560\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.7335 - acc: 0.6601 - val_loss: 1.7276 - val_acc: 0.6630\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.6974 - acc: 0.6721 - val_loss: 1.6943 - val_acc: 0.6670\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.6631 - acc: 0.6823 - val_loss: 1.6624 - val_acc: 0.6790\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 1.6310 - acc: 0.6909 - val_loss: 1.6332 - val_acc: 0.6820\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.6008 - acc: 0.7001 - val_loss: 1.6055 - val_acc: 0.6900\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.5722 - acc: 0.7047 - val_loss: 1.5802 - val_acc: 0.6960\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.5450 - acc: 0.7095 - val_loss: 1.5597 - val_acc: 0.7020\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.5198 - acc: 0.7164 - val_loss: 1.5361 - val_acc: 0.7050\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.4961 - acc: 0.7201 - val_loss: 1.5162 - val_acc: 0.7070\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.4735 - acc: 0.7272 - val_loss: 1.4969 - val_acc: 0.7110\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.4530 - acc: 0.7301 - val_loss: 1.4757 - val_acc: 0.7120\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.4332 - acc: 0.7327 - val_loss: 1.4635 - val_acc: 0.7140\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.4145 - acc: 0.7377 - val_loss: 1.4437 - val_acc: 0.7210\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.3970 - acc: 0.7413 - val_loss: 1.4288 - val_acc: 0.7200\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.3805 - acc: 0.7459 - val_loss: 1.4155 - val_acc: 0.7260\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.3649 - acc: 0.7476 - val_loss: 1.4030 - val_acc: 0.7240\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.3502 - acc: 0.7492 - val_loss: 1.3913 - val_acc: 0.7250\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.3360 - acc: 0.7539 - val_loss: 1.3800 - val_acc: 0.7320\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.3228 - acc: 0.7596 - val_loss: 1.3716 - val_acc: 0.7270\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.3099 - acc: 0.7633 - val_loss: 1.3591 - val_acc: 0.7330\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2976 - acc: 0.7669 - val_loss: 1.3549 - val_acc: 0.7230\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2856 - acc: 0.7707 - val_loss: 1.3440 - val_acc: 0.7270\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2745 - acc: 0.7707 - val_loss: 1.3333 - val_acc: 0.7310\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.2639 - acc: 0.7755 - val_loss: 1.3241 - val_acc: 0.7350\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.2533 - acc: 0.7745 - val_loss: 1.3203 - val_acc: 0.7280\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.2431 - acc: 0.7785 - val_loss: 1.3106 - val_acc: 0.7350\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.2330 - acc: 0.7821 - val_loss: 1.3059 - val_acc: 0.7330\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.2241 - acc: 0.7871 - val_loss: 1.2999 - val_acc: 0.7310\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.2148 - acc: 0.7864 - val_loss: 1.2935 - val_acc: 0.7350\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.2059 - acc: 0.7893 - val_loss: 1.2823 - val_acc: 0.7440\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.1968 - acc: 0.7923 - val_loss: 1.2784 - val_acc: 0.7370\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.1886 - acc: 0.7933 - val_loss: 1.2732 - val_acc: 0.7460\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.1803 - acc: 0.7976 - val_loss: 1.2645 - val_acc: 0.7440\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.1721 - acc: 0.8000 - val_loss: 1.2630 - val_acc: 0.7430\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.1647 - acc: 0.8009 - val_loss: 1.2552 - val_acc: 0.7430\n",
      "Epoch 56/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.1570 - acc: 0.8023 - val_loss: 1.2503 - val_acc: 0.7440\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.1497 - acc: 0.8028 - val_loss: 1.2452 - val_acc: 0.7470\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.1422 - acc: 0.8053 - val_loss: 1.2408 - val_acc: 0.7470\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.1350 - acc: 0.8077 - val_loss: 1.2357 - val_acc: 0.7470\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.1282 - acc: 0.8084 - val_loss: 1.2307 - val_acc: 0.7460\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.1214 - acc: 0.8097 - val_loss: 1.2267 - val_acc: 0.7460\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 1.1145 - acc: 0.8133 - val_loss: 1.2206 - val_acc: 0.7500\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.1078 - acc: 0.8116 - val_loss: 1.2183 - val_acc: 0.7540\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.1016 - acc: 0.8181 - val_loss: 1.2148 - val_acc: 0.7490\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.0954 - acc: 0.8152 - val_loss: 1.2105 - val_acc: 0.7530\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.0889 - acc: 0.8195 - val_loss: 1.2071 - val_acc: 0.7500\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.0827 - acc: 0.8207 - val_loss: 1.2038 - val_acc: 0.7540\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.0769 - acc: 0.8228 - val_loss: 1.1986 - val_acc: 0.7550\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.0708 - acc: 0.8232 - val_loss: 1.1943 - val_acc: 0.7520\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0651 - acc: 0.8225 - val_loss: 1.1899 - val_acc: 0.7570\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0587 - acc: 0.8272 - val_loss: 1.1898 - val_acc: 0.7480\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0534 - acc: 0.8271 - val_loss: 1.1846 - val_acc: 0.7500\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.0478 - acc: 0.8297 - val_loss: 1.1806 - val_acc: 0.7540\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.0425 - acc: 0.8300 - val_loss: 1.1784 - val_acc: 0.7490\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.0372 - acc: 0.8301 - val_loss: 1.1730 - val_acc: 0.7510\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.0316 - acc: 0.8315 - val_loss: 1.1699 - val_acc: 0.7540\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.0264 - acc: 0.8343 - val_loss: 1.1691 - val_acc: 0.7520\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.0209 - acc: 0.8364 - val_loss: 1.1684 - val_acc: 0.7550\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.0158 - acc: 0.8361 - val_loss: 1.1617 - val_acc: 0.7570\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.0105 - acc: 0.8383 - val_loss: 1.1642 - val_acc: 0.7550\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.0058 - acc: 0.8363 - val_loss: 1.1612 - val_acc: 0.7530\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.0009 - acc: 0.8412 - val_loss: 1.1538 - val_acc: 0.7520\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.9960 - acc: 0.8409 - val_loss: 1.1504 - val_acc: 0.7550\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.9907 - acc: 0.8439 - val_loss: 1.1482 - val_acc: 0.7570\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9859 - acc: 0.8440 - val_loss: 1.1448 - val_acc: 0.7650\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9813 - acc: 0.8467 - val_loss: 1.1483 - val_acc: 0.7570\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.9766 - acc: 0.8457 - val_loss: 1.1385 - val_acc: 0.7570\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.9718 - acc: 0.8471 - val_loss: 1.1394 - val_acc: 0.7560\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.9672 - acc: 0.8488 - val_loss: 1.1330 - val_acc: 0.7620\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.9626 - acc: 0.8509 - val_loss: 1.1315 - val_acc: 0.7580\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.9578 - acc: 0.8497 - val_loss: 1.1294 - val_acc: 0.7600\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.9538 - acc: 0.8521 - val_loss: 1.1288 - val_acc: 0.7660\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9493 - acc: 0.8537 - val_loss: 1.1244 - val_acc: 0.7580\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.9447 - acc: 0.8553 - val_loss: 1.1215 - val_acc: 0.7620\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.9406 - acc: 0.8539 - val_loss: 1.1212 - val_acc: 0.7600\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.9363 - acc: 0.8564 - val_loss: 1.1162 - val_acc: 0.7580\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9320 - acc: 0.8568 - val_loss: 1.1159 - val_acc: 0.7590\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9279 - acc: 0.8587 - val_loss: 1.1143 - val_acc: 0.7590\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.9236 - acc: 0.8585 - val_loss: 1.1124 - val_acc: 0.7620\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.9195 - acc: 0.8589 - val_loss: 1.1098 - val_acc: 0.7620\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.9154 - acc: 0.8615 - val_loss: 1.1052 - val_acc: 0.7610\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.9113 - acc: 0.8627 - val_loss: 1.1034 - val_acc: 0.7660\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.9074 - acc: 0.8649 - val_loss: 1.1058 - val_acc: 0.7590\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.9036 - acc: 0.8665 - val_loss: 1.0990 - val_acc: 0.7630\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.8997 - acc: 0.8667 - val_loss: 1.0978 - val_acc: 0.7630\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8955 - acc: 0.8679 - val_loss: 1.0992 - val_acc: 0.7620\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8918 - acc: 0.8679 - val_loss: 1.0923 - val_acc: 0.7660\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8881 - acc: 0.8696 - val_loss: 1.0900 - val_acc: 0.7690\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8842 - acc: 0.8692 - val_loss: 1.0892 - val_acc: 0.7660\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.8802 - acc: 0.8715 - val_loss: 1.0859 - val_acc: 0.7670\n",
      "Epoch 111/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8766 - acc: 0.8723 - val_loss: 1.0839 - val_acc: 0.7690\n",
      "Epoch 112/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8729 - acc: 0.8737 - val_loss: 1.0825 - val_acc: 0.7670\n",
      "Epoch 113/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8691 - acc: 0.8753 - val_loss: 1.0864 - val_acc: 0.7660\n",
      "Epoch 114/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8657 - acc: 0.8741 - val_loss: 1.0791 - val_acc: 0.7700\n",
      "Epoch 115/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8618 - acc: 0.8761 - val_loss: 1.0818 - val_acc: 0.7640\n",
      "Epoch 116/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.8585 - acc: 0.8735 - val_loss: 1.0773 - val_acc: 0.7700\n",
      "Epoch 117/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8551 - acc: 0.8777 - val_loss: 1.0744 - val_acc: 0.7660\n",
      "Epoch 118/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.8512 - acc: 0.8796 - val_loss: 1.0740 - val_acc: 0.7680\n",
      "Epoch 119/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.8474 - acc: 0.8784 - val_loss: 1.0726 - val_acc: 0.7720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8441 - acc: 0.8797 - val_loss: 1.0808 - val_acc: 0.7670\n",
      "Epoch 121/150\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.8409 - acc: 0.8817 - val_loss: 1.0682 - val_acc: 0.7690\n",
      "Epoch 122/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8374 - acc: 0.8816 - val_loss: 1.0646 - val_acc: 0.7680\n",
      "Epoch 123/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.8341 - acc: 0.8825 - val_loss: 1.0661 - val_acc: 0.7700\n",
      "Epoch 124/150\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 0.8304 - acc: 0.8840 - val_loss: 1.0638 - val_acc: 0.7690\n",
      "Epoch 125/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.8273 - acc: 0.8829 - val_loss: 1.0626 - val_acc: 0.7710\n",
      "Epoch 126/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 0.8240 - acc: 0.8837 - val_loss: 1.0610 - val_acc: 0.7660\n",
      "Epoch 127/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8209 - acc: 0.8881 - val_loss: 1.0590 - val_acc: 0.7720\n",
      "Epoch 128/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.8175 - acc: 0.8881 - val_loss: 1.0622 - val_acc: 0.7740\n",
      "Epoch 129/150\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.8145 - acc: 0.8876 - val_loss: 1.0570 - val_acc: 0.7700\n",
      "Epoch 130/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 0.8110 - acc: 0.8873 - val_loss: 1.0527 - val_acc: 0.7670\n",
      "Epoch 131/150\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.8079 - acc: 0.8897 - val_loss: 1.0569 - val_acc: 0.7690\n",
      "Epoch 132/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8050 - acc: 0.8907 - val_loss: 1.0526 - val_acc: 0.7730\n",
      "Epoch 133/150\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 0.8019 - acc: 0.8901 - val_loss: 1.0524 - val_acc: 0.7710\n",
      "Epoch 134/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.7986 - acc: 0.8920 - val_loss: 1.0484 - val_acc: 0.7670\n",
      "Epoch 135/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.7953 - acc: 0.8924 - val_loss: 1.0461 - val_acc: 0.7680\n",
      "Epoch 136/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.7925 - acc: 0.8936 - val_loss: 1.0478 - val_acc: 0.7690\n",
      "Epoch 137/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.7896 - acc: 0.8936 - val_loss: 1.0438 - val_acc: 0.7730\n",
      "Epoch 138/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.7864 - acc: 0.8945 - val_loss: 1.0432 - val_acc: 0.7730\n",
      "Epoch 139/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.7832 - acc: 0.8955 - val_loss: 1.0427 - val_acc: 0.7690\n",
      "Epoch 140/150\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.7804 - acc: 0.8969 - val_loss: 1.0451 - val_acc: 0.7680\n",
      "Epoch 141/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.7777 - acc: 0.8961 - val_loss: 1.0425 - val_acc: 0.7690\n",
      "Epoch 142/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.7746 - acc: 0.8976 - val_loss: 1.0383 - val_acc: 0.7750\n",
      "Epoch 143/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.7714 - acc: 0.8991 - val_loss: 1.0398 - val_acc: 0.7700\n",
      "Epoch 144/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.7687 - acc: 0.8985 - val_loss: 1.0400 - val_acc: 0.7710\n",
      "Epoch 145/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.7660 - acc: 0.9011 - val_loss: 1.0364 - val_acc: 0.7690\n",
      "Epoch 146/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.7627 - acc: 0.8996 - val_loss: 1.0340 - val_acc: 0.7750\n",
      "Epoch 147/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.7605 - acc: 0.9016 - val_loss: 1.0343 - val_acc: 0.7700\n",
      "Epoch 148/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.7576 - acc: 0.9024 - val_loss: 1.0324 - val_acc: 0.7690\n",
      "Epoch 149/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.7548 - acc: 0.9029 - val_loss: 1.0345 - val_acc: 0.7730\n",
      "Epoch 150/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.7521 - acc: 0.9039 - val_loss: 1.0291 - val_acc: 0.7670\n"
     ]
    }
   ],
   "source": [
    "# Import regularizers\n",
    "from keras import regularizers\n",
    "\n",
    "random.seed(123)\n",
    "L2_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L2_model.add(layers.Dense(50, activation = 'relu', input_shape = (2000,), kernel_regularizer = regularizers.l2(.005)))\n",
    "\n",
    "# Add another hidden layer\n",
    "L2_model.add(layers.Dense(25, activation = 'relu', kernel_regularizer = regularizers.l2(.005)))\n",
    "\n",
    "\n",
    "# Add an output layer\n",
    "L2_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L2_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "L2_model_val = L2_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=256, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the training as well as the validation accuracy for both the L2 and the baseline models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# L2 model details\n",
    "L2_model_dict = L2_model_val.history\n",
    "L2_acc_values = L2_model_dict['acc'] \n",
    "L2_val_acc_values = L2_model_dict['val_acc']\n",
    "\n",
    "# Baseline model\n",
    "baseline_model_acc = baseline_model_val_dict['acc'] \n",
    "baseline_model_val_acc = baseline_model_val_dict['val_acc']\n",
    "\n",
    "# Plot the accuracy for these models\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "epochs = range(1, len(L2_acc_values) + 1)\n",
    "ax.plot(epochs, L2_acc_values, label='Training acc L2')\n",
    "ax.plot(epochs, L2_val_acc_values, label='Validation acc L2')\n",
    "ax.plot(epochs, baseline_model_acc, label='Training acc')\n",
    "ax.plot(epochs, baseline_model_val_acc, label='Validation acc')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of L2 regularization are quite disappointing here. Notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better.  \n",
    "\n",
    "\n",
    "## L1 Regularization\n",
    "\n",
    "Now have a look at L1 regularization. Will this work better? \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L1 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 15.9657 - acc: 0.1728 - val_loss: 15.5649 - val_acc: 0.1770\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 15.2127 - acc: 0.2079 - val_loss: 14.8247 - val_acc: 0.2120\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 14.4815 - acc: 0.2423 - val_loss: 14.1052 - val_acc: 0.2330\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 13.7695 - acc: 0.2541 - val_loss: 13.4045 - val_acc: 0.2360\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 13.0772 - acc: 0.2593 - val_loss: 12.7238 - val_acc: 0.2550\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 12.4052 - acc: 0.2671 - val_loss: 12.0621 - val_acc: 0.2800\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 11.7527 - acc: 0.2911 - val_loss: 11.4198 - val_acc: 0.2930\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 11.1193 - acc: 0.3093 - val_loss: 10.7971 - val_acc: 0.3180\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 10.5060 - acc: 0.3305 - val_loss: 10.1944 - val_acc: 0.3410\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 9.9132 - acc: 0.3439 - val_loss: 9.6129 - val_acc: 0.3520\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 9.3424 - acc: 0.3553 - val_loss: 9.0532 - val_acc: 0.3620\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 8.7935 - acc: 0.3692 - val_loss: 8.5158 - val_acc: 0.3700\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 8.2660 - acc: 0.3795 - val_loss: 7.9996 - val_acc: 0.3740\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 7.7600 - acc: 0.3861 - val_loss: 7.5054 - val_acc: 0.3970\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 7.2756 - acc: 0.4047 - val_loss: 7.0334 - val_acc: 0.4120\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 6.8136 - acc: 0.4183 - val_loss: 6.5831 - val_acc: 0.4280\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 6.3738 - acc: 0.4299 - val_loss: 6.1561 - val_acc: 0.4490\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 5.9571 - acc: 0.4483 - val_loss: 5.7516 - val_acc: 0.4560\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 5.5627 - acc: 0.4619 - val_loss: 5.3698 - val_acc: 0.4700\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 5.1915 - acc: 0.4735 - val_loss: 5.0108 - val_acc: 0.4820\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 4.8431 - acc: 0.4929 - val_loss: 4.6753 - val_acc: 0.4890\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 4.5169 - acc: 0.4999 - val_loss: 4.3604 - val_acc: 0.5010\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 4.2134 - acc: 0.5155 - val_loss: 4.0683 - val_acc: 0.5120\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 3.9319 - acc: 0.5235 - val_loss: 3.7996 - val_acc: 0.5200\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 3.6727 - acc: 0.5333 - val_loss: 3.5532 - val_acc: 0.5250\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 3.4358 - acc: 0.5389 - val_loss: 3.3259 - val_acc: 0.5490\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 3.2200 - acc: 0.5513 - val_loss: 3.1225 - val_acc: 0.5630\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 3.0262 - acc: 0.5577 - val_loss: 2.9399 - val_acc: 0.5800\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 2.8527 - acc: 0.5672 - val_loss: 2.7779 - val_acc: 0.5660\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 2.6999 - acc: 0.5745 - val_loss: 2.6370 - val_acc: 0.5670\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 2.5677 - acc: 0.5755 - val_loss: 2.5141 - val_acc: 0.5750\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 2.4548 - acc: 0.5808 - val_loss: 2.4138 - val_acc: 0.5880\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 2.3618 - acc: 0.5876 - val_loss: 2.3301 - val_acc: 0.5790\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.2874 - acc: 0.5927 - val_loss: 2.2659 - val_acc: 0.5940\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 2.2304 - acc: 0.6005 - val_loss: 2.2175 - val_acc: 0.5980\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 2.1879 - acc: 0.6039 - val_loss: 2.1812 - val_acc: 0.5980\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 2.1571 - acc: 0.6092 - val_loss: 2.1550 - val_acc: 0.5980\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 2.1320 - acc: 0.6128 - val_loss: 2.1338 - val_acc: 0.6110\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 2.1098 - acc: 0.6239 - val_loss: 2.1141 - val_acc: 0.6080\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 2.0890 - acc: 0.6221 - val_loss: 2.0930 - val_acc: 0.6080\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 2.0694 - acc: 0.6265 - val_loss: 2.0736 - val_acc: 0.6180\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 2.0503 - acc: 0.6325 - val_loss: 2.0550 - val_acc: 0.6210\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 2.0320 - acc: 0.6373 - val_loss: 2.0395 - val_acc: 0.6280\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 2.0139 - acc: 0.6419 - val_loss: 2.0199 - val_acc: 0.6310\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 1.9965 - acc: 0.6452 - val_loss: 2.0032 - val_acc: 0.6360\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.9794 - acc: 0.6484 - val_loss: 1.9920 - val_acc: 0.6230\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.9631 - acc: 0.6501 - val_loss: 1.9730 - val_acc: 0.6450\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.9471 - acc: 0.6556 - val_loss: 1.9553 - val_acc: 0.6460\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.9310 - acc: 0.6569 - val_loss: 1.9421 - val_acc: 0.6470\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.9152 - acc: 0.6589 - val_loss: 1.9271 - val_acc: 0.6570\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.9001 - acc: 0.6648 - val_loss: 1.9122 - val_acc: 0.6530\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.8850 - acc: 0.6651 - val_loss: 1.8984 - val_acc: 0.6520\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.8702 - acc: 0.6679 - val_loss: 1.8844 - val_acc: 0.6530\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.8564 - acc: 0.6679 - val_loss: 1.8712 - val_acc: 0.6560\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.8424 - acc: 0.6700 - val_loss: 1.8582 - val_acc: 0.6540\n",
      "Epoch 56/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.8283 - acc: 0.6729 - val_loss: 1.8449 - val_acc: 0.6680\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.8147 - acc: 0.6745 - val_loss: 1.8319 - val_acc: 0.6570\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.8016 - acc: 0.6759 - val_loss: 1.8202 - val_acc: 0.6630\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.7885 - acc: 0.6777 - val_loss: 1.8068 - val_acc: 0.6600\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.7759 - acc: 0.6789 - val_loss: 1.7940 - val_acc: 0.6690\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.7635 - acc: 0.6779 - val_loss: 1.7834 - val_acc: 0.6740\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.7507 - acc: 0.6800 - val_loss: 1.7734 - val_acc: 0.6670\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.7391 - acc: 0.6819 - val_loss: 1.7610 - val_acc: 0.6690\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.7273 - acc: 0.6817 - val_loss: 1.7494 - val_acc: 0.6680\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.7158 - acc: 0.6848 - val_loss: 1.7437 - val_acc: 0.6710\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.7046 - acc: 0.6851 - val_loss: 1.7292 - val_acc: 0.6640\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.6932 - acc: 0.6876 - val_loss: 1.7188 - val_acc: 0.6630\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.6831 - acc: 0.6880 - val_loss: 1.7102 - val_acc: 0.6690\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.6720 - acc: 0.6879 - val_loss: 1.6991 - val_acc: 0.6690\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.6620 - acc: 0.6896 - val_loss: 1.6889 - val_acc: 0.6640\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.6518 - acc: 0.6924 - val_loss: 1.6808 - val_acc: 0.6620\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.6425 - acc: 0.6924 - val_loss: 1.6725 - val_acc: 0.6690\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.6327 - acc: 0.6923 - val_loss: 1.6635 - val_acc: 0.6650\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.6229 - acc: 0.6943 - val_loss: 1.6563 - val_acc: 0.6710\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.6137 - acc: 0.6943 - val_loss: 1.6474 - val_acc: 0.6710\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.6047 - acc: 0.6949 - val_loss: 1.6373 - val_acc: 0.6700\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.5953 - acc: 0.6960 - val_loss: 1.6334 - val_acc: 0.6780\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.5870 - acc: 0.6975 - val_loss: 1.6215 - val_acc: 0.6670\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.5783 - acc: 0.6980 - val_loss: 1.6167 - val_acc: 0.6710\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.5700 - acc: 0.6987 - val_loss: 1.6055 - val_acc: 0.6780\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.5614 - acc: 0.7001 - val_loss: 1.6010 - val_acc: 0.6680\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.5532 - acc: 0.7007 - val_loss: 1.5914 - val_acc: 0.6750\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.5455 - acc: 0.7007 - val_loss: 1.5827 - val_acc: 0.6740\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.5372 - acc: 0.7009 - val_loss: 1.5770 - val_acc: 0.6750\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.5292 - acc: 0.7045 - val_loss: 1.5679 - val_acc: 0.6760\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.5216 - acc: 0.7045 - val_loss: 1.5605 - val_acc: 0.6810\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.5141 - acc: 0.7045 - val_loss: 1.5554 - val_acc: 0.6810\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.5065 - acc: 0.7057 - val_loss: 1.5486 - val_acc: 0.6850\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.4992 - acc: 0.7047 - val_loss: 1.5442 - val_acc: 0.6860\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.4921 - acc: 0.7061 - val_loss: 1.5366 - val_acc: 0.6780\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.4852 - acc: 0.7065 - val_loss: 1.5293 - val_acc: 0.6820\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 1.4778 - acc: 0.7092 - val_loss: 1.5213 - val_acc: 0.6850\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.4710 - acc: 0.7088 - val_loss: 1.5167 - val_acc: 0.6850\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.4645 - acc: 0.7100 - val_loss: 1.5091 - val_acc: 0.6880\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.4576 - acc: 0.7087 - val_loss: 1.5048 - val_acc: 0.6920\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.4513 - acc: 0.7109 - val_loss: 1.5030 - val_acc: 0.6850\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.4451 - acc: 0.7097 - val_loss: 1.4934 - val_acc: 0.6910\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.4385 - acc: 0.7136 - val_loss: 1.4886 - val_acc: 0.6920\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.4321 - acc: 0.7107 - val_loss: 1.4803 - val_acc: 0.6920\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.4258 - acc: 0.7123 - val_loss: 1.4750 - val_acc: 0.6910\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.4199 - acc: 0.7128 - val_loss: 1.4687 - val_acc: 0.6920\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.4134 - acc: 0.7145 - val_loss: 1.4620 - val_acc: 0.6950\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.4074 - acc: 0.7129 - val_loss: 1.4583 - val_acc: 0.6930\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.4017 - acc: 0.7164 - val_loss: 1.4553 - val_acc: 0.6930\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.3960 - acc: 0.7144 - val_loss: 1.4485 - val_acc: 0.6920\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.3901 - acc: 0.7140 - val_loss: 1.4416 - val_acc: 0.6980\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.3843 - acc: 0.7173 - val_loss: 1.4421 - val_acc: 0.7000\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3787 - acc: 0.7165 - val_loss: 1.4341 - val_acc: 0.6940\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.3730 - acc: 0.7163 - val_loss: 1.4251 - val_acc: 0.6980\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3671 - acc: 0.7187 - val_loss: 1.4231 - val_acc: 0.6990\n",
      "Epoch 111/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3621 - acc: 0.7185 - val_loss: 1.4187 - val_acc: 0.7010\n",
      "Epoch 112/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.3572 - acc: 0.7185 - val_loss: 1.4116 - val_acc: 0.7000\n",
      "Epoch 113/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.3514 - acc: 0.7189 - val_loss: 1.4095 - val_acc: 0.6990\n",
      "Epoch 114/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.3468 - acc: 0.7204 - val_loss: 1.4032 - val_acc: 0.6990\n",
      "Epoch 115/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.3413 - acc: 0.7196 - val_loss: 1.4035 - val_acc: 0.6970\n",
      "Epoch 116/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.3368 - acc: 0.7199 - val_loss: 1.3951 - val_acc: 0.7020\n",
      "Epoch 117/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3314 - acc: 0.7193 - val_loss: 1.3885 - val_acc: 0.7010\n",
      "Epoch 118/150\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.3260 - acc: 0.7220 - val_loss: 1.3863 - val_acc: 0.7040\n",
      "Epoch 119/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3211 - acc: 0.7225 - val_loss: 1.3804 - val_acc: 0.7010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.3164 - acc: 0.7220 - val_loss: 1.3752 - val_acc: 0.7050\n",
      "Epoch 121/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.3115 - acc: 0.7227 - val_loss: 1.3686 - val_acc: 0.7030\n",
      "Epoch 122/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.3067 - acc: 0.7229 - val_loss: 1.3749 - val_acc: 0.6990\n",
      "Epoch 123/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.3020 - acc: 0.7220 - val_loss: 1.3623 - val_acc: 0.7050\n",
      "Epoch 124/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.2965 - acc: 0.7247 - val_loss: 1.3599 - val_acc: 0.7090\n",
      "Epoch 125/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.2925 - acc: 0.7251 - val_loss: 1.3567 - val_acc: 0.7080\n",
      "Epoch 126/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.2882 - acc: 0.7255 - val_loss: 1.3533 - val_acc: 0.7020\n",
      "Epoch 127/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2836 - acc: 0.7264 - val_loss: 1.3457 - val_acc: 0.7080\n",
      "Epoch 128/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.2787 - acc: 0.7268 - val_loss: 1.3390 - val_acc: 0.7060\n",
      "Epoch 129/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2745 - acc: 0.7256 - val_loss: 1.3346 - val_acc: 0.7100\n",
      "Epoch 130/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2706 - acc: 0.7261 - val_loss: 1.3313 - val_acc: 0.7060\n",
      "Epoch 131/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.2653 - acc: 0.7277 - val_loss: 1.3281 - val_acc: 0.7070\n",
      "Epoch 132/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.2614 - acc: 0.7285 - val_loss: 1.3231 - val_acc: 0.7090\n",
      "Epoch 133/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.2571 - acc: 0.7277 - val_loss: 1.3203 - val_acc: 0.7090\n",
      "Epoch 134/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.2527 - acc: 0.7279 - val_loss: 1.3169 - val_acc: 0.7110\n",
      "Epoch 135/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.2491 - acc: 0.7275 - val_loss: 1.3170 - val_acc: 0.7100\n",
      "Epoch 136/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2452 - acc: 0.7284 - val_loss: 1.3131 - val_acc: 0.7080\n",
      "Epoch 137/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.2406 - acc: 0.7276 - val_loss: 1.3053 - val_acc: 0.7090\n",
      "Epoch 138/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.2369 - acc: 0.7303 - val_loss: 1.3039 - val_acc: 0.7070\n",
      "Epoch 139/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.2328 - acc: 0.7292 - val_loss: 1.2999 - val_acc: 0.7100\n",
      "Epoch 140/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2292 - acc: 0.7293 - val_loss: 1.2953 - val_acc: 0.7090\n",
      "Epoch 141/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.2250 - acc: 0.7308 - val_loss: 1.2897 - val_acc: 0.7110\n",
      "Epoch 142/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.2210 - acc: 0.7305 - val_loss: 1.2881 - val_acc: 0.7130\n",
      "Epoch 143/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.2174 - acc: 0.7317 - val_loss: 1.2840 - val_acc: 0.7130\n",
      "Epoch 144/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2138 - acc: 0.7315 - val_loss: 1.2831 - val_acc: 0.7090\n",
      "Epoch 145/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2106 - acc: 0.7323 - val_loss: 1.2761 - val_acc: 0.7120\n",
      "Epoch 146/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2066 - acc: 0.7357 - val_loss: 1.2753 - val_acc: 0.7140\n",
      "Epoch 147/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.2035 - acc: 0.7325 - val_loss: 1.2709 - val_acc: 0.7090\n",
      "Epoch 148/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.1997 - acc: 0.7313 - val_loss: 1.2658 - val_acc: 0.7140\n",
      "Epoch 149/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.1959 - acc: 0.7335 - val_loss: 1.2631 - val_acc: 0.7080\n",
      "Epoch 150/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.1924 - acc: 0.7344 - val_loss: 1.2610 - val_acc: 0.7150\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "L1_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L1_model.add(layers.Dense(50, activation = 'relu', input_shape = (2000,), kernel_regularizer = regularizers.l1(.005)))\n",
    "\n",
    "# Add a hidden layer\n",
    "L1_model.add(layers.Dense(25, activation = 'relu', kernel_regularizer = regularizers.l1(.005)))\n",
    "\n",
    "# Add an output layer\n",
    "L1_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L1_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "L1_model_val = L1_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=256, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training as well as the validation accuracy for the L1 model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model_val.history\n",
    "\n",
    "acc_values = L1_model_dict['acc'] \n",
    "val_acc_values = L1_model_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy with L1 regularization')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the training and validation accuracy don't diverge as much as before. Unfortunately, the validation accuracy isn't still that good. Next, experiment with dropout regularization to see if it offers any advantages. \n",
    "\n",
    "\n",
    "## Dropout Regularization \n",
    "\n",
    "It's time to try another technique: applying dropout to layers. As discussed in the earlier lesson, this involves setting a certain proportion of units in each layer to zero. In the following cell: \n",
    "\n",
    "- Apply a dropout rate of 30% to the input layer \n",
    "- Add a first hidden layer with 50 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the first hidden layer \n",
    "- Add a second hidden layer with 25 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the second hidden layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 1s 117us/step - loss: 1.9647 - acc: 0.1424 - val_loss: 1.9320 - val_acc: 0.1730\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.9414 - acc: 0.1661 - val_loss: 1.9182 - val_acc: 0.1990\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.9254 - acc: 0.1817 - val_loss: 1.9064 - val_acc: 0.2130\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 1.9163 - acc: 0.1955 - val_loss: 1.8956 - val_acc: 0.2140\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.9095 - acc: 0.1943 - val_loss: 1.8858 - val_acc: 0.2220\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 1.8970 - acc: 0.2073 - val_loss: 1.8752 - val_acc: 0.2300\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.8831 - acc: 0.2203 - val_loss: 1.8626 - val_acc: 0.2330\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.8759 - acc: 0.2300 - val_loss: 1.8497 - val_acc: 0.2500\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 1.8651 - acc: 0.2343 - val_loss: 1.8361 - val_acc: 0.2640\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.8534 - acc: 0.2468 - val_loss: 1.8207 - val_acc: 0.2740\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.8467 - acc: 0.2504 - val_loss: 1.8037 - val_acc: 0.2950\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 1.8294 - acc: 0.2632 - val_loss: 1.7853 - val_acc: 0.3070\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.8179 - acc: 0.2676 - val_loss: 1.7649 - val_acc: 0.3240\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 1.8002 - acc: 0.2805 - val_loss: 1.7428 - val_acc: 0.3470\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.7846 - acc: 0.2877 - val_loss: 1.7201 - val_acc: 0.3710\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 1.7657 - acc: 0.2939 - val_loss: 1.6953 - val_acc: 0.3860\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.7557 - acc: 0.3021 - val_loss: 1.6717 - val_acc: 0.4070\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 1.7371 - acc: 0.3180 - val_loss: 1.6493 - val_acc: 0.4180\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 1.7221 - acc: 0.3271 - val_loss: 1.6246 - val_acc: 0.4340\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.7006 - acc: 0.3277 - val_loss: 1.6003 - val_acc: 0.4530\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.6810 - acc: 0.3413 - val_loss: 1.5761 - val_acc: 0.4630\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.6634 - acc: 0.3541 - val_loss: 1.5520 - val_acc: 0.4700\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 1.6493 - acc: 0.3539 - val_loss: 1.5280 - val_acc: 0.4870\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.6212 - acc: 0.3680 - val_loss: 1.5024 - val_acc: 0.5000\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 1.6075 - acc: 0.3667 - val_loss: 1.4791 - val_acc: 0.5160\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 1.5972 - acc: 0.3787 - val_loss: 1.4561 - val_acc: 0.5330\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.5726 - acc: 0.3889 - val_loss: 1.4346 - val_acc: 0.5390\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 1.5621 - acc: 0.3996 - val_loss: 1.4162 - val_acc: 0.5570\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.5492 - acc: 0.4020 - val_loss: 1.3972 - val_acc: 0.5630\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 1.5310 - acc: 0.4132 - val_loss: 1.3748 - val_acc: 0.5740\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.5170 - acc: 0.4149 - val_loss: 1.3558 - val_acc: 0.5810\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.5049 - acc: 0.4259 - val_loss: 1.3365 - val_acc: 0.5900\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 1.4847 - acc: 0.4324 - val_loss: 1.3157 - val_acc: 0.5980\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 1.4734 - acc: 0.4371 - val_loss: 1.2971 - val_acc: 0.6050\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 1.4634 - acc: 0.4341 - val_loss: 1.2808 - val_acc: 0.6140\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.4417 - acc: 0.4509 - val_loss: 1.2631 - val_acc: 0.6190\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 1.4304 - acc: 0.4509 - val_loss: 1.2463 - val_acc: 0.6270\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 1.4348 - acc: 0.4452 - val_loss: 1.2320 - val_acc: 0.6360\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.4043 - acc: 0.4635 - val_loss: 1.2145 - val_acc: 0.6410\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.4006 - acc: 0.4600 - val_loss: 1.2001 - val_acc: 0.6430\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 1.3809 - acc: 0.4767 - val_loss: 1.1846 - val_acc: 0.6480\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 1.3740 - acc: 0.4796 - val_loss: 1.1713 - val_acc: 0.6530\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 1.3621 - acc: 0.4787 - val_loss: 1.1568 - val_acc: 0.6560\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 1.3474 - acc: 0.4857 - val_loss: 1.1424 - val_acc: 0.6550\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 1.3366 - acc: 0.4921 - val_loss: 1.1293 - val_acc: 0.6580\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 1.3392 - acc: 0.4861 - val_loss: 1.1200 - val_acc: 0.6640\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 1.3273 - acc: 0.4901 - val_loss: 1.1063 - val_acc: 0.6700\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 1.2981 - acc: 0.5083 - val_loss: 1.0911 - val_acc: 0.6670\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.3076 - acc: 0.4989 - val_loss: 1.0851 - val_acc: 0.6820\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.2982 - acc: 0.5064 - val_loss: 1.0705 - val_acc: 0.6810\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.2841 - acc: 0.5049 - val_loss: 1.0579 - val_acc: 0.6820\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.2655 - acc: 0.5229 - val_loss: 1.0457 - val_acc: 0.6880\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.2646 - acc: 0.5191 - val_loss: 1.0352 - val_acc: 0.6920\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 1.2536 - acc: 0.5249 - val_loss: 1.0251 - val_acc: 0.6910\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 1.2575 - acc: 0.5189 - val_loss: 1.0181 - val_acc: 0.6950\n",
      "Epoch 56/150\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 1.2382 - acc: 0.5291 - val_loss: 1.0077 - val_acc: 0.6970\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.2247 - acc: 0.5337 - val_loss: 0.9980 - val_acc: 0.6980\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 1.2176 - acc: 0.5333 - val_loss: 0.9888 - val_acc: 0.7070\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 1.2056 - acc: 0.5412 - val_loss: 0.9795 - val_acc: 0.7060\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.2107 - acc: 0.5369 - val_loss: 0.9715 - val_acc: 0.7120\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.1969 - acc: 0.5495 - val_loss: 0.9654 - val_acc: 0.7140\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.1938 - acc: 0.5496 - val_loss: 0.9555 - val_acc: 0.7150\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 1.1830 - acc: 0.5521 - val_loss: 0.9490 - val_acc: 0.7110\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 1.1822 - acc: 0.5541 - val_loss: 0.9398 - val_acc: 0.7160\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 1.1773 - acc: 0.5560 - val_loss: 0.9339 - val_acc: 0.7210\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 1.1535 - acc: 0.5649 - val_loss: 0.9246 - val_acc: 0.7210\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 1.1622 - acc: 0.5612 - val_loss: 0.9177 - val_acc: 0.7230\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.1575 - acc: 0.5569 - val_loss: 0.9146 - val_acc: 0.7270\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 1.1355 - acc: 0.5732 - val_loss: 0.9042 - val_acc: 0.7320\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 1.1373 - acc: 0.5668 - val_loss: 0.8964 - val_acc: 0.7310\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.1227 - acc: 0.5787 - val_loss: 0.8908 - val_acc: 0.7310\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 1.1255 - acc: 0.5736 - val_loss: 0.8859 - val_acc: 0.7320\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.1098 - acc: 0.5823 - val_loss: 0.8778 - val_acc: 0.7320\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.1114 - acc: 0.5752 - val_loss: 0.8729 - val_acc: 0.7330\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.1189 - acc: 0.5759 - val_loss: 0.8696 - val_acc: 0.7370\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 1.1081 - acc: 0.5773 - val_loss: 0.8664 - val_acc: 0.7360\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 1.0998 - acc: 0.5849 - val_loss: 0.8592 - val_acc: 0.7390\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 1.0872 - acc: 0.5889 - val_loss: 0.8530 - val_acc: 0.7400\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 1.0825 - acc: 0.5944 - val_loss: 0.8467 - val_acc: 0.7360\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 1.0799 - acc: 0.5948 - val_loss: 0.8411 - val_acc: 0.7370\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 1.0692 - acc: 0.5943 - val_loss: 0.8381 - val_acc: 0.7350\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.0720 - acc: 0.6015 - val_loss: 0.8334 - val_acc: 0.7370\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 1.0657 - acc: 0.5993 - val_loss: 0.8300 - val_acc: 0.7400\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.0618 - acc: 0.6128 - val_loss: 0.8230 - val_acc: 0.7400\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 1.0545 - acc: 0.6100 - val_loss: 0.8191 - val_acc: 0.7390\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 1.0488 - acc: 0.6069 - val_loss: 0.8150 - val_acc: 0.7350\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.0351 - acc: 0.6120 - val_loss: 0.8116 - val_acc: 0.7410\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 1.0284 - acc: 0.6148 - val_loss: 0.8076 - val_acc: 0.7450\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.0197 - acc: 0.6163 - val_loss: 0.8002 - val_acc: 0.7380\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 1.0250 - acc: 0.6099 - val_loss: 0.7951 - val_acc: 0.7450\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 1.0226 - acc: 0.6179 - val_loss: 0.7919 - val_acc: 0.7430\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 1.0207 - acc: 0.6200 - val_loss: 0.7878 - val_acc: 0.7400\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 1.0175 - acc: 0.6145 - val_loss: 0.7842 - val_acc: 0.7420\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.0146 - acc: 0.6203 - val_loss: 0.7820 - val_acc: 0.7410\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 1.0103 - acc: 0.6259 - val_loss: 0.7759 - val_acc: 0.7400\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 1.0046 - acc: 0.6247 - val_loss: 0.7733 - val_acc: 0.7390\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 0.9955 - acc: 0.6275 - val_loss: 0.7722 - val_acc: 0.7410\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 0.9785 - acc: 0.6313 - val_loss: 0.7669 - val_acc: 0.7430\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.9956 - acc: 0.6192 - val_loss: 0.7633 - val_acc: 0.7400\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 0.9815 - acc: 0.6328 - val_loss: 0.7597 - val_acc: 0.7390\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.9838 - acc: 0.6333 - val_loss: 0.7556 - val_acc: 0.7410\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 0.9780 - acc: 0.6299 - val_loss: 0.7524 - val_acc: 0.7440\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 0.9759 - acc: 0.6367 - val_loss: 0.7511 - val_acc: 0.7450\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 0.9674 - acc: 0.6420 - val_loss: 0.7458 - val_acc: 0.7390\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 0.9651 - acc: 0.6369 - val_loss: 0.7422 - val_acc: 0.7420\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.9748 - acc: 0.6365 - val_loss: 0.7420 - val_acc: 0.7430\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.9624 - acc: 0.6393 - val_loss: 0.7390 - val_acc: 0.7430\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 0.9615 - acc: 0.6376 - val_loss: 0.7368 - val_acc: 0.7450\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.9672 - acc: 0.6403 - val_loss: 0.7361 - val_acc: 0.7460\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.9516 - acc: 0.6480 - val_loss: 0.7324 - val_acc: 0.7420\n",
      "Epoch 111/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 0.9499 - acc: 0.6396 - val_loss: 0.7277 - val_acc: 0.7470\n",
      "Epoch 112/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.9546 - acc: 0.6499 - val_loss: 0.7277 - val_acc: 0.7470\n",
      "Epoch 113/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.9472 - acc: 0.6417 - val_loss: 0.7249 - val_acc: 0.7460\n",
      "Epoch 114/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 0.9406 - acc: 0.6463 - val_loss: 0.7226 - val_acc: 0.7510\n",
      "Epoch 115/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 0.9419 - acc: 0.6504 - val_loss: 0.7198 - val_acc: 0.7530\n",
      "Epoch 116/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.9323 - acc: 0.6535 - val_loss: 0.7184 - val_acc: 0.7480\n",
      "Epoch 117/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.9317 - acc: 0.6539 - val_loss: 0.7162 - val_acc: 0.7530\n",
      "Epoch 118/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 0.9352 - acc: 0.6511 - val_loss: 0.7130 - val_acc: 0.7520\n",
      "Epoch 119/150\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.9138 - acc: 0.6616 - val_loss: 0.7087 - val_acc: 0.7540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 0.9267 - acc: 0.6573 - val_loss: 0.7070 - val_acc: 0.7540\n",
      "Epoch 121/150\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.9166 - acc: 0.6591 - val_loss: 0.7042 - val_acc: 0.7520\n",
      "Epoch 122/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 0.9284 - acc: 0.6543 - val_loss: 0.7063 - val_acc: 0.7470\n",
      "Epoch 123/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 0.9067 - acc: 0.6631 - val_loss: 0.7010 - val_acc: 0.7510\n",
      "Epoch 124/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 0.8974 - acc: 0.6712 - val_loss: 0.6983 - val_acc: 0.7540\n",
      "Epoch 125/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 0.9113 - acc: 0.6551 - val_loss: 0.6961 - val_acc: 0.7520\n",
      "Epoch 126/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.8986 - acc: 0.6624 - val_loss: 0.6950 - val_acc: 0.7520\n",
      "Epoch 127/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 0.8834 - acc: 0.6712 - val_loss: 0.6913 - val_acc: 0.7550\n",
      "Epoch 128/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 0.8943 - acc: 0.6667 - val_loss: 0.6900 - val_acc: 0.7550\n",
      "Epoch 129/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 0.8862 - acc: 0.6711 - val_loss: 0.6887 - val_acc: 0.7560\n",
      "Epoch 130/150\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.8825 - acc: 0.6769 - val_loss: 0.6847 - val_acc: 0.7560\n",
      "Epoch 131/150\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 0.8837 - acc: 0.6737 - val_loss: 0.6842 - val_acc: 0.7520\n",
      "Epoch 132/150\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.8749 - acc: 0.6733 - val_loss: 0.6812 - val_acc: 0.7560\n",
      "Epoch 133/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 0.8790 - acc: 0.6765 - val_loss: 0.6800 - val_acc: 0.7560\n",
      "Epoch 134/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 0.8673 - acc: 0.6811 - val_loss: 0.6790 - val_acc: 0.7570\n",
      "Epoch 135/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.8778 - acc: 0.6711 - val_loss: 0.6774 - val_acc: 0.7620\n",
      "Epoch 136/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 0.8843 - acc: 0.6741 - val_loss: 0.6775 - val_acc: 0.7600\n",
      "Epoch 137/150\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 0.8726 - acc: 0.6789 - val_loss: 0.6756 - val_acc: 0.7600\n",
      "Epoch 138/150\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.8735 - acc: 0.6777 - val_loss: 0.6740 - val_acc: 0.7610\n",
      "Epoch 139/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 0.8589 - acc: 0.6875 - val_loss: 0.6717 - val_acc: 0.7590\n",
      "Epoch 140/150\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 0.8719 - acc: 0.6755 - val_loss: 0.6701 - val_acc: 0.7610\n",
      "Epoch 141/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 0.8583 - acc: 0.6825 - val_loss: 0.6694 - val_acc: 0.7610\n",
      "Epoch 142/150\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.8497 - acc: 0.6861 - val_loss: 0.6686 - val_acc: 0.7610\n",
      "Epoch 143/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 0.8525 - acc: 0.6831 - val_loss: 0.6662 - val_acc: 0.7590\n",
      "Epoch 144/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 0.8424 - acc: 0.6804 - val_loss: 0.6640 - val_acc: 0.7600\n",
      "Epoch 145/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 0.8511 - acc: 0.6873 - val_loss: 0.6635 - val_acc: 0.7610\n",
      "Epoch 146/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 0.8545 - acc: 0.6776 - val_loss: 0.6609 - val_acc: 0.7580\n",
      "Epoch 147/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 0.8437 - acc: 0.6831 - val_loss: 0.6581 - val_acc: 0.7630\n",
      "Epoch 148/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 0.8661 - acc: 0.6821 - val_loss: 0.6591 - val_acc: 0.7630\n",
      "Epoch 149/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.8429 - acc: 0.6791 - val_loss: 0.6599 - val_acc: 0.7630\n",
      "Epoch 150/150\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 0.8364 - acc: 0.6884 - val_loss: 0.6583 - val_acc: 0.7650\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take about a minute to run\n",
    "from keras.layers import Dropout\n",
    "random.seed(123)\n",
    "dropout_model = models.Sequential()\n",
    "\n",
    "# Implement dropout to the input layer\n",
    "# NOTE: This is where you define the number of units in the input layer\n",
    "dropout_model.add(Dropout(0.3, input_shape=(2000,)))\n",
    "\n",
    "# Add the first hidden layer\n",
    "dropout_model.add(layers.Dense(50, activation = 'relu'))\n",
    "\n",
    "# Implement dropout to the first hidden layer \n",
    "dropout_model.add(Dropout(0.3))\n",
    "\n",
    "# Add the second hidden layer\n",
    "dropout_model.add(layers.Dense(25, activation = 'relu'))\n",
    "\n",
    "# Implement dropout to the second hidden layer \n",
    "dropout_model.add(Dropout(0.3))\n",
    "\n",
    "# Add the output layer\n",
    "dropout_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "dropout_model.compile(optimizer='SGD', \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "dropout_model_val = dropout_model.fit(X_train_tokens, \n",
    "                                      y_train_lb, \n",
    "                                      epochs=150, \n",
    "                                      batch_size=256, \n",
    "                                      validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 50us/step\n",
      "Training Loss: 0.554 \n",
      "Training Accuracy: 0.815\n",
      "----------\n",
      "1500/1500 [==============================] - 0s 47us/step\n",
      "Test Loss: 0.674 \n",
      "Test Accuracy: 0.744\n"
     ]
    }
   ],
   "source": [
    "results_train = dropout_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = dropout_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the validation performance has improved again, and the training and test accuracy are very close!  \n",
    "\n",
    "## Bigger Data? \n",
    "\n",
    "Finally, let's examine if we can improve the model's performance just by adding more data. We've quadrapled the sample dataset from 10,000 to 40,000 observations, and all you need to do is run the code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigger_sample = df.sample(40000, random_state=123)\n",
    "\n",
    "X = df['consumer_complaint_narrative']\n",
    "y = df['product']\n",
    "\n",
    "# Train-test split\n",
    "X_train_bigger, X_test_bigger, y_train_bigger, y_test_bigger = train_test_split(X, \n",
    "                                                                                y, \n",
    "                                                                                test_size=6000, \n",
    "                                                                                random_state=42)\n",
    "\n",
    "# Validation set\n",
    "X_train_final_bigger, X_val_bigger, y_train_final_bigger, y_val_bigger = train_test_split(X_train_bigger, \n",
    "                                                                                          y_train_bigger, \n",
    "                                                                                          test_size=4000, \n",
    "                                                                                          random_state=42)\n",
    "\n",
    "\n",
    "# One-hot encoding of the complaints\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final_bigger)\n",
    "\n",
    "X_train_tokens_bigger = tokenizer.texts_to_matrix(X_train_final_bigger, mode='binary')\n",
    "X_val_tokens_bigger = tokenizer.texts_to_matrix(X_val_bigger, mode='binary')\n",
    "X_test_tokens_bigger = tokenizer.texts_to_matrix(X_test_bigger, mode='binary')\n",
    "\n",
    "# One-hot encoding of products\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final_bigger)\n",
    "\n",
    "y_train_lb_bigger = to_categorical(lb.transform(y_train_final_bigger))[:, :, 1]\n",
    "y_val_lb_bigger = to_categorical(lb.transform(y_val_bigger))[:, :, 1]\n",
    "y_test_lb_bigger = to_categorical(lb.transform(y_test_bigger))[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 4000 samples\n",
      "Epoch 1/150\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.9127 - acc: 0.2148 - val_loss: 1.8598 - val_acc: 0.2858\n",
      "Epoch 2/150\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 1.7715 - acc: 0.3466 - val_loss: 1.6655 - val_acc: 0.4145\n",
      "Epoch 3/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 1.5183 - acc: 0.4785 - val_loss: 1.3803 - val_acc: 0.5440\n",
      "Epoch 4/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 1.2361 - acc: 0.6081 - val_loss: 1.1220 - val_acc: 0.6553\n",
      "Epoch 5/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.0166 - acc: 0.6750 - val_loss: 0.9481 - val_acc: 0.6923\n",
      "Epoch 6/150\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.8745 - acc: 0.7056 - val_loss: 0.8411 - val_acc: 0.7088\n",
      "Epoch 7/150\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.7853 - acc: 0.7249 - val_loss: 0.7719 - val_acc: 0.7260\n",
      "Epoch 8/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.7274 - acc: 0.7389 - val_loss: 0.7294 - val_acc: 0.7383\n",
      "Epoch 9/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.6870 - acc: 0.7502 - val_loss: 0.7021 - val_acc: 0.7452\n",
      "Epoch 10/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.6574 - acc: 0.7581 - val_loss: 0.6754 - val_acc: 0.7565\n",
      "Epoch 11/150\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.6341 - acc: 0.7660 - val_loss: 0.6602 - val_acc: 0.7582\n",
      "Epoch 12/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.6152 - acc: 0.7724 - val_loss: 0.6455 - val_acc: 0.7632\n",
      "Epoch 13/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.5990 - acc: 0.7790 - val_loss: 0.6314 - val_acc: 0.7675\n",
      "Epoch 14/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5853 - acc: 0.7841 - val_loss: 0.6218 - val_acc: 0.7698\n",
      "Epoch 15/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.5730 - acc: 0.7894 - val_loss: 0.6133 - val_acc: 0.7733\n",
      "Epoch 16/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.5624 - acc: 0.7934 - val_loss: 0.6058 - val_acc: 0.7770\n",
      "Epoch 17/150\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.5522 - acc: 0.7979 - val_loss: 0.5986 - val_acc: 0.7780\n",
      "Epoch 18/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.5436 - acc: 0.8011 - val_loss: 0.5919 - val_acc: 0.7842\n",
      "Epoch 19/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.5351 - acc: 0.8049 - val_loss: 0.5868 - val_acc: 0.7855\n",
      "Epoch 20/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.5275 - acc: 0.8089 - val_loss: 0.5828 - val_acc: 0.7875\n",
      "Epoch 21/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5203 - acc: 0.8120 - val_loss: 0.5800 - val_acc: 0.7875\n",
      "Epoch 22/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.5137 - acc: 0.8140 - val_loss: 0.5728 - val_acc: 0.7928\n",
      "Epoch 23/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.5072 - acc: 0.8163 - val_loss: 0.5713 - val_acc: 0.7908\n",
      "Epoch 24/150\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.5015 - acc: 0.8180 - val_loss: 0.5665 - val_acc: 0.7942\n",
      "Epoch 25/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4957 - acc: 0.8214 - val_loss: 0.5649 - val_acc: 0.7965\n",
      "Epoch 26/150\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.4903 - acc: 0.8229 - val_loss: 0.5651 - val_acc: 0.7962\n",
      "Epoch 27/150\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4857 - acc: 0.8243 - val_loss: 0.5613 - val_acc: 0.7953\n",
      "Epoch 28/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4807 - acc: 0.8256 - val_loss: 0.5605 - val_acc: 0.7950\n",
      "Epoch 29/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4763 - acc: 0.8281 - val_loss: 0.5562 - val_acc: 0.7998\n",
      "Epoch 30/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4717 - acc: 0.8305 - val_loss: 0.5521 - val_acc: 0.8007\n",
      "Epoch 31/150\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.4678 - acc: 0.8321 - val_loss: 0.5550 - val_acc: 0.7972\n",
      "Epoch 32/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.4639 - acc: 0.8329 - val_loss: 0.5502 - val_acc: 0.8010\n",
      "Epoch 33/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4599 - acc: 0.8351 - val_loss: 0.5508 - val_acc: 0.8017\n",
      "Epoch 34/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.4566 - acc: 0.8357 - val_loss: 0.5471 - val_acc: 0.8017\n",
      "Epoch 35/150\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.4533 - acc: 0.8373 - val_loss: 0.5466 - val_acc: 0.8043\n",
      "Epoch 36/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.4497 - acc: 0.8384 - val_loss: 0.5461 - val_acc: 0.8067\n",
      "Epoch 37/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4466 - acc: 0.8397 - val_loss: 0.5450 - val_acc: 0.8055\n",
      "Epoch 38/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.4437 - acc: 0.8410 - val_loss: 0.5425 - val_acc: 0.8093\n",
      "Epoch 39/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4402 - acc: 0.8425 - val_loss: 0.5434 - val_acc: 0.8090\n",
      "Epoch 40/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4374 - acc: 0.8443 - val_loss: 0.5440 - val_acc: 0.8057\n",
      "Epoch 41/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.4348 - acc: 0.8448 - val_loss: 0.5392 - val_acc: 0.8065\n",
      "Epoch 42/150\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.4320 - acc: 0.8462 - val_loss: 0.5389 - val_acc: 0.8080\n",
      "Epoch 43/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4292 - acc: 0.8472 - val_loss: 0.5378 - val_acc: 0.8098\n",
      "Epoch 44/150\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.4268 - acc: 0.8487 - val_loss: 0.5377 - val_acc: 0.8090\n",
      "Epoch 45/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.4243 - acc: 0.8489 - val_loss: 0.5407 - val_acc: 0.8095\n",
      "Epoch 46/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4219 - acc: 0.8503 - val_loss: 0.5382 - val_acc: 0.8113\n",
      "Epoch 47/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4194 - acc: 0.8507 - val_loss: 0.5386 - val_acc: 0.8070\n",
      "Epoch 48/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.4172 - acc: 0.8514 - val_loss: 0.5395 - val_acc: 0.8087\n",
      "Epoch 49/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.4150 - acc: 0.8530 - val_loss: 0.5367 - val_acc: 0.8070\n",
      "Epoch 50/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4128 - acc: 0.8531 - val_loss: 0.5436 - val_acc: 0.8078\n",
      "Epoch 51/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.4109 - acc: 0.8542 - val_loss: 0.5355 - val_acc: 0.8113\n",
      "Epoch 52/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4086 - acc: 0.8551 - val_loss: 0.5343 - val_acc: 0.8105\n",
      "Epoch 53/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4067 - acc: 0.8555 - val_loss: 0.5367 - val_acc: 0.8100\n",
      "Epoch 54/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.4049 - acc: 0.8565 - val_loss: 0.5355 - val_acc: 0.8115\n",
      "Epoch 55/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.4029 - acc: 0.8573 - val_loss: 0.5364 - val_acc: 0.8108\n",
      "Epoch 56/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4009 - acc: 0.8586 - val_loss: 0.5365 - val_acc: 0.8118\n",
      "Epoch 57/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3990 - acc: 0.8586 - val_loss: 0.5369 - val_acc: 0.8103\n",
      "Epoch 58/150\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.3973 - acc: 0.8583 - val_loss: 0.5370 - val_acc: 0.8075\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3956 - acc: 0.8604 - val_loss: 0.5403 - val_acc: 0.8120\n",
      "Epoch 60/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3939 - acc: 0.8609 - val_loss: 0.5361 - val_acc: 0.8088\n",
      "Epoch 61/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.3921 - acc: 0.8609 - val_loss: 0.5397 - val_acc: 0.8100\n",
      "Epoch 62/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3905 - acc: 0.8616 - val_loss: 0.5381 - val_acc: 0.8095\n",
      "Epoch 63/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3887 - acc: 0.8625 - val_loss: 0.5363 - val_acc: 0.8065\n",
      "Epoch 64/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3872 - acc: 0.8630 - val_loss: 0.5384 - val_acc: 0.8108\n",
      "Epoch 65/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3856 - acc: 0.8636 - val_loss: 0.5373 - val_acc: 0.8107\n",
      "Epoch 66/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3840 - acc: 0.8643 - val_loss: 0.5412 - val_acc: 0.8108\n",
      "Epoch 67/150\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.3829 - acc: 0.8656 - val_loss: 0.5398 - val_acc: 0.8097\n",
      "Epoch 68/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3811 - acc: 0.8648 - val_loss: 0.5396 - val_acc: 0.8112\n",
      "Epoch 69/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3796 - acc: 0.8665 - val_loss: 0.5472 - val_acc: 0.8047\n",
      "Epoch 70/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3786 - acc: 0.8665 - val_loss: 0.5409 - val_acc: 0.8122\n",
      "Epoch 71/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3769 - acc: 0.8673 - val_loss: 0.5409 - val_acc: 0.8085\n",
      "Epoch 72/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3755 - acc: 0.8676 - val_loss: 0.5412 - val_acc: 0.8127\n",
      "Epoch 73/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3739 - acc: 0.8684 - val_loss: 0.5425 - val_acc: 0.8065\n",
      "Epoch 74/150\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.3731 - acc: 0.8684 - val_loss: 0.5406 - val_acc: 0.8077\n",
      "Epoch 75/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3718 - acc: 0.8686 - val_loss: 0.5452 - val_acc: 0.8105\n",
      "Epoch 76/150\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.3701 - acc: 0.8701 - val_loss: 0.5405 - val_acc: 0.8103\n",
      "Epoch 77/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3688 - acc: 0.8705 - val_loss: 0.5436 - val_acc: 0.8085\n",
      "Epoch 78/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3673 - acc: 0.8711 - val_loss: 0.5476 - val_acc: 0.8035\n",
      "Epoch 79/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3663 - acc: 0.8713 - val_loss: 0.5443 - val_acc: 0.8053\n",
      "Epoch 80/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3651 - acc: 0.8714 - val_loss: 0.5456 - val_acc: 0.8095\n",
      "Epoch 81/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.3642 - acc: 0.8723 - val_loss: 0.5449 - val_acc: 0.8087\n",
      "Epoch 82/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3628 - acc: 0.8726 - val_loss: 0.5501 - val_acc: 0.8047\n",
      "Epoch 83/150\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.3617 - acc: 0.8739 - val_loss: 0.5454 - val_acc: 0.8085\n",
      "Epoch 84/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3604 - acc: 0.8739 - val_loss: 0.5470 - val_acc: 0.8073\n",
      "Epoch 85/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3595 - acc: 0.8744 - val_loss: 0.5477 - val_acc: 0.8100\n",
      "Epoch 86/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3580 - acc: 0.8740 - val_loss: 0.5510 - val_acc: 0.8055\n",
      "Epoch 87/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3571 - acc: 0.8748 - val_loss: 0.5512 - val_acc: 0.8080\n",
      "Epoch 88/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3560 - acc: 0.8754 - val_loss: 0.5486 - val_acc: 0.8055\n",
      "Epoch 89/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3549 - acc: 0.8746 - val_loss: 0.5557 - val_acc: 0.8053\n",
      "Epoch 90/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3535 - acc: 0.8761 - val_loss: 0.5488 - val_acc: 0.8088\n",
      "Epoch 91/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.3523 - acc: 0.8766 - val_loss: 0.5502 - val_acc: 0.8100\n",
      "Epoch 92/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3515 - acc: 0.8767 - val_loss: 0.5532 - val_acc: 0.8070\n",
      "Epoch 93/150\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.3505 - acc: 0.8766 - val_loss: 0.5558 - val_acc: 0.8065\n",
      "Epoch 94/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3496 - acc: 0.8771 - val_loss: 0.5531 - val_acc: 0.8110\n",
      "Epoch 95/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3480 - acc: 0.8782 - val_loss: 0.5537 - val_acc: 0.8092\n",
      "Epoch 96/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3473 - acc: 0.8784 - val_loss: 0.5510 - val_acc: 0.8083\n",
      "Epoch 97/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3462 - acc: 0.8779 - val_loss: 0.5562 - val_acc: 0.8055\n",
      "Epoch 98/150\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.3454 - acc: 0.8788 - val_loss: 0.5593 - val_acc: 0.8062\n",
      "Epoch 99/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3441 - acc: 0.8797 - val_loss: 0.5541 - val_acc: 0.8098\n",
      "Epoch 100/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3428 - acc: 0.8802 - val_loss: 0.5561 - val_acc: 0.8095\n",
      "Epoch 101/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.3423 - acc: 0.8794 - val_loss: 0.5574 - val_acc: 0.8113\n",
      "Epoch 102/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3413 - acc: 0.8801 - val_loss: 0.5647 - val_acc: 0.8082\n",
      "Epoch 103/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3403 - acc: 0.8809 - val_loss: 0.5578 - val_acc: 0.8067\n",
      "Epoch 104/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.3391 - acc: 0.8811 - val_loss: 0.5639 - val_acc: 0.8067\n",
      "Epoch 105/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.3385 - acc: 0.8818 - val_loss: 0.5608 - val_acc: 0.8075\n",
      "Epoch 106/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3376 - acc: 0.8815 - val_loss: 0.5597 - val_acc: 0.8115\n",
      "Epoch 107/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3368 - acc: 0.8822 - val_loss: 0.5630 - val_acc: 0.8073\n",
      "Epoch 108/150\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.3356 - acc: 0.8819 - val_loss: 0.5682 - val_acc: 0.8077\n",
      "Epoch 109/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3350 - acc: 0.8826 - val_loss: 0.5632 - val_acc: 0.8095\n",
      "Epoch 110/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3334 - acc: 0.8828 - val_loss: 0.5677 - val_acc: 0.8080\n",
      "Epoch 111/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3328 - acc: 0.8834 - val_loss: 0.5612 - val_acc: 0.8075\n",
      "Epoch 112/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3318 - acc: 0.8840 - val_loss: 0.5667 - val_acc: 0.8045\n",
      "Epoch 113/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3311 - acc: 0.8843 - val_loss: 0.5673 - val_acc: 0.8063\n",
      "Epoch 114/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.3302 - acc: 0.8841 - val_loss: 0.5659 - val_acc: 0.8052\n",
      "Epoch 115/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3293 - acc: 0.8847 - val_loss: 0.5658 - val_acc: 0.8065\n",
      "Epoch 116/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3283 - acc: 0.8849 - val_loss: 0.5721 - val_acc: 0.8078\n",
      "Epoch 117/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3272 - acc: 0.8855 - val_loss: 0.5680 - val_acc: 0.8078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.3265 - acc: 0.8857 - val_loss: 0.5721 - val_acc: 0.8063\n",
      "Epoch 119/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3253 - acc: 0.8861 - val_loss: 0.5708 - val_acc: 0.8090\n",
      "Epoch 120/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3245 - acc: 0.8860 - val_loss: 0.5709 - val_acc: 0.8103\n",
      "Epoch 121/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.3237 - acc: 0.8866 - val_loss: 0.5708 - val_acc: 0.8098\n",
      "Epoch 122/150\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.3229 - acc: 0.8870 - val_loss: 0.5702 - val_acc: 0.8068\n",
      "Epoch 123/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.3222 - acc: 0.8872 - val_loss: 0.5701 - val_acc: 0.8085\n",
      "Epoch 124/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3211 - acc: 0.8875 - val_loss: 0.5718 - val_acc: 0.8058\n",
      "Epoch 125/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.3203 - acc: 0.8878 - val_loss: 0.5787 - val_acc: 0.8015\n",
      "Epoch 126/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3194 - acc: 0.8887 - val_loss: 0.5816 - val_acc: 0.8030\n",
      "Epoch 127/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3186 - acc: 0.8887 - val_loss: 0.5796 - val_acc: 0.8050\n",
      "Epoch 128/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.3178 - acc: 0.8887 - val_loss: 0.5895 - val_acc: 0.8017\n",
      "Epoch 129/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3169 - acc: 0.8897 - val_loss: 0.5763 - val_acc: 0.8082\n",
      "Epoch 130/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3158 - acc: 0.8893 - val_loss: 0.5780 - val_acc: 0.8060\n",
      "Epoch 131/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3150 - acc: 0.8895 - val_loss: 0.5796 - val_acc: 0.8078\n",
      "Epoch 132/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.3143 - acc: 0.8900 - val_loss: 0.5774 - val_acc: 0.8088\n",
      "Epoch 133/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3133 - acc: 0.8907 - val_loss: 0.5819 - val_acc: 0.8063\n",
      "Epoch 134/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3125 - acc: 0.8910 - val_loss: 0.5829 - val_acc: 0.8020\n",
      "Epoch 135/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3117 - acc: 0.8910 - val_loss: 0.5848 - val_acc: 0.8057\n",
      "Epoch 136/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3106 - acc: 0.8922 - val_loss: 0.5820 - val_acc: 0.8097\n",
      "Epoch 137/150\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.3098 - acc: 0.8929 - val_loss: 0.5839 - val_acc: 0.8090\n",
      "Epoch 138/150\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.3087 - acc: 0.8930 - val_loss: 0.5867 - val_acc: 0.8027\n",
      "Epoch 139/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.3081 - acc: 0.8933 - val_loss: 0.6088 - val_acc: 0.7987\n",
      "Epoch 140/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3071 - acc: 0.8937 - val_loss: 0.5845 - val_acc: 0.8065\n",
      "Epoch 141/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3062 - acc: 0.8939 - val_loss: 0.5859 - val_acc: 0.8042\n",
      "Epoch 142/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.3052 - acc: 0.8941 - val_loss: 0.5960 - val_acc: 0.8030\n",
      "Epoch 143/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3050 - acc: 0.8938 - val_loss: 0.5894 - val_acc: 0.8100\n",
      "Epoch 144/150\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.3035 - acc: 0.8948 - val_loss: 0.5978 - val_acc: 0.8070\n",
      "Epoch 145/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3030 - acc: 0.8954 - val_loss: 0.5971 - val_acc: 0.8040\n",
      "Epoch 146/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3018 - acc: 0.8942 - val_loss: 0.5949 - val_acc: 0.8047\n",
      "Epoch 147/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.3010 - acc: 0.8957 - val_loss: 0.5891 - val_acc: 0.8092\n",
      "Epoch 148/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3002 - acc: 0.8963 - val_loss: 0.6008 - val_acc: 0.8005\n",
      "Epoch 149/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.2991 - acc: 0.8967 - val_loss: 0.5981 - val_acc: 0.8072\n",
      "Epoch 150/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.2983 - acc: 0.8974 - val_loss: 0.6130 - val_acc: 0.7970\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "bigger_data_model = models.Sequential()\n",
    "bigger_data_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "bigger_data_model.add(layers.Dense(25, activation='relu'))\n",
    "bigger_data_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "bigger_data_model.compile(optimizer='SGD', \n",
    "                          loss='categorical_crossentropy', \n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "bigger_data_model_val = bigger_data_model.fit(X_train_tokens_bigger,  \n",
    "                                              y_train_lb_bigger,  \n",
    "                                              epochs=150,  \n",
    "                                              batch_size=256,  \n",
    "                                              validation_data=(X_val_tokens_bigger, y_val_lb_bigger))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 47us/step\n",
      "Training Loss: 0.307 \n",
      "Training Accuracy: 0.889\n",
      "----------\n",
      "4000/4000 [==============================] - 0s 39us/step\n",
      "Test Loss: 0.613 \n",
      "Test Accuracy: 0.797\n"
     ]
    }
   ],
   "source": [
    "results_train = bigger_data_model.evaluate(X_train_tokens_bigger, y_train_lb_bigger)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = bigger_data_model.evaluate(X_val_tokens_bigger, y_val_lb_bigger)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same amount of epochs and no regularization technique, you were able to get both better test accuracy and loss. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance! \n",
    "\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n",
    "* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "* https://catalog.data.gov/dataset/consumer-complaint-database \n",
    "\n",
    "\n",
    "## Summary  \n",
    "\n",
    "In this lesson, you built deep learning models using a validation set and used several techniques such as L2 and L1 regularization, dropout regularization, and early stopping to improve the accuracy of your models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
